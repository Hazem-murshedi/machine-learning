{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset: [UCF101](https://www.crcv.ucf.edu/research/data-sets/ucf101/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from random import shuffle\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n"
     ]
    }
   ],
   "source": [
    "# Check availability of GPU\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False # Uncomment in case of GPU memory error\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories containing extracted features\n",
    "trainPath = 'ucf101_resnet18Feat/train/'\n",
    "testPath = 'ucf101_resnet18Feat/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train list for loading feature tensors\n",
    "classes = os.listdir(trainPath)\n",
    "classes.sort()\n",
    "labels = np.arange(5)\n",
    "trainShuffList = []\n",
    "labelShuffList = []\n",
    "for c in range(5):\n",
    "    files = os.listdir(trainPath+classes[c])\n",
    "    for f in files:\n",
    "        trainShuffList.append(classes[c]+'/'+f)  \n",
    "        labelShuffList.append(float(labels[c]))\n",
    "# Shuffling data list and label list\n",
    "trainList = list(zip(trainShuffList, labelShuffList))\n",
    "shuffle(trainList)\n",
    "trainShuffList, labelShuffList = zip(*trainList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating test list for loading feature tensors\n",
    "testList = []\n",
    "testLabelList = []\n",
    "for c in range(5):\n",
    "    files = os.listdir(testPath+classes[c])\n",
    "    for f in files:\n",
    "        testList.append(classes[c]+'/'+f)  \n",
    "        testLabelList.append(float(labels[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net_LSTM(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_sz, nLayers, nClasses):\n",
    "        super(net_LSTM, self).__init__()       \n",
    "        self.lstm = nn.LSTM(input_sz, hidden_sz, nLayers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_sz, nClasses)        \n",
    "    \n",
    "    def forward(self, x):      \n",
    "        out, _ = self.lstm(x)       \n",
    "        # Output from hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, inputs, labels, optimizer, criterion):\n",
    "    net.train()\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # Feed-forward\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)     \n",
    "    # Initialize gradients to zero\n",
    "    optimizer.zero_grad() \n",
    "    # Compute loss/error\n",
    "    loss = criterion(F.log_softmax(outputs,dim=1), labels)\n",
    "    # Backpropagate loss and compute gradients\n",
    "    loss.backward()\n",
    "    # Update the network parameters\n",
    "    optimizer.step()\n",
    "    correct = (predicted == labels.data).sum()\n",
    "    if use_gpu:\n",
    "        correct = correct.cpu()   \n",
    "    return net, loss.item(), correct    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define test routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " def test(net, inputs, labels, criterion):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "        # Compute loss/error\n",
    "        loss = criterion(F.log_softmax(outputs,dim=1), labels)   \n",
    "        correct = (predicted == labels.data).sum()\n",
    "        if use_gpu:\n",
    "            correct = correct.cpu()\n",
    "    return loss.item(), correct    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_LSTM(\n",
      "  (lstm): LSTM(512, 8, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=8, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = net_LSTM(512, 8, 2, 5).to(device) # Input feature length->512, hidden layer size->8, number of layers->2\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # Negative Log-likelihood\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4) # Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 /1000;  Training Loss: 1.757777 ; Training Acc: 17.417\n",
      "Iteration: 1 /1000;  Testing Loss: 2.095549 ; Testing Acc: 23.308\n",
      "Time consumed: 0m 5s\n",
      "Iteration: 2 /1000;  Training Loss: 1.752737 ; Training Acc: 17.417\n",
      "Iteration: 2 /1000;  Testing Loss: 2.091961 ; Testing Acc: 22.556\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 3 /1000;  Training Loss: 1.748763 ; Training Acc: 17.417\n",
      "Iteration: 3 /1000;  Testing Loss: 2.089439 ; Testing Acc: 24.060\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 4 /1000;  Training Loss: 1.746236 ; Training Acc: 17.417\n",
      "Iteration: 4 /1000;  Testing Loss: 2.087646 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 5 /1000;  Training Loss: 1.744258 ; Training Acc: 17.417\n",
      "Iteration: 5 /1000;  Testing Loss: 2.086777 ; Testing Acc: 21.053\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 6 /1000;  Training Loss: 1.741040 ; Training Acc: 17.417\n",
      "Iteration: 6 /1000;  Testing Loss: 2.084837 ; Testing Acc: 23.308\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 7 /1000;  Training Loss: 1.736934 ; Training Acc: 17.417\n",
      "Iteration: 7 /1000;  Testing Loss: 2.082568 ; Testing Acc: 22.556\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 8 /1000;  Training Loss: 1.731764 ; Training Acc: 17.221\n",
      "Iteration: 8 /1000;  Testing Loss: 2.079296 ; Testing Acc: 24.060\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 9 /1000;  Training Loss: 1.728250 ; Training Acc: 21.918\n",
      "Iteration: 9 /1000;  Testing Loss: 2.076282 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 10 /1000;  Training Loss: 1.725073 ; Training Acc: 22.701\n",
      "Iteration: 10 /1000;  Testing Loss: 2.074664 ; Testing Acc: 23.308\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 11 /1000;  Training Loss: 1.722802 ; Training Acc: 22.701\n",
      "Iteration: 11 /1000;  Testing Loss: 2.074283 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 12 /1000;  Training Loss: 1.721122 ; Training Acc: 22.701\n",
      "Iteration: 12 /1000;  Testing Loss: 2.075319 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 13 /1000;  Training Loss: 1.719453 ; Training Acc: 22.701\n",
      "Iteration: 13 /1000;  Testing Loss: 2.077179 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 14 /1000;  Training Loss: 1.717827 ; Training Acc: 22.701\n",
      "Iteration: 14 /1000;  Testing Loss: 2.078456 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 15 /1000;  Training Loss: 1.716878 ; Training Acc: 22.701\n",
      "Iteration: 15 /1000;  Testing Loss: 2.082193 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 16 /1000;  Training Loss: 1.716165 ; Training Acc: 22.701\n",
      "Iteration: 16 /1000;  Testing Loss: 2.082773 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 17 /1000;  Training Loss: 1.715137 ; Training Acc: 22.701\n",
      "Iteration: 17 /1000;  Testing Loss: 2.083325 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 18 /1000;  Training Loss: 1.714773 ; Training Acc: 22.701\n",
      "Iteration: 18 /1000;  Testing Loss: 2.081654 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 19 /1000;  Training Loss: 1.714394 ; Training Acc: 22.701\n",
      "Iteration: 19 /1000;  Testing Loss: 2.081285 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 20 /1000;  Training Loss: 1.714037 ; Training Acc: 22.701\n",
      "Iteration: 20 /1000;  Testing Loss: 2.081333 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 21 /1000;  Training Loss: 1.713659 ; Training Acc: 22.701\n",
      "Iteration: 21 /1000;  Testing Loss: 2.080975 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 22 /1000;  Training Loss: 1.713283 ; Training Acc: 22.701\n",
      "Iteration: 22 /1000;  Testing Loss: 2.079897 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 23 /1000;  Training Loss: 1.713366 ; Training Acc: 22.701\n",
      "Iteration: 23 /1000;  Testing Loss: 2.078482 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 24 /1000;  Training Loss: 1.712768 ; Training Acc: 22.701\n",
      "Iteration: 24 /1000;  Testing Loss: 2.078432 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 25 /1000;  Training Loss: 1.712679 ; Training Acc: 22.701\n",
      "Iteration: 25 /1000;  Testing Loss: 2.077986 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 26 /1000;  Training Loss: 1.712535 ; Training Acc: 22.701\n",
      "Iteration: 26 /1000;  Testing Loss: 2.077902 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 27 /1000;  Training Loss: 1.712201 ; Training Acc: 22.701\n",
      "Iteration: 27 /1000;  Testing Loss: 2.075737 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 28 /1000;  Training Loss: 1.712028 ; Training Acc: 22.701\n",
      "Iteration: 28 /1000;  Testing Loss: 2.075414 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 29 /1000;  Training Loss: 1.711724 ; Training Acc: 22.701\n",
      "Iteration: 29 /1000;  Testing Loss: 2.074189 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 30 /1000;  Training Loss: 1.711623 ; Training Acc: 22.701\n",
      "Iteration: 30 /1000;  Testing Loss: 2.073398 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 31 /1000;  Training Loss: 1.711380 ; Training Acc: 22.701\n",
      "Iteration: 31 /1000;  Testing Loss: 2.071832 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 32 /1000;  Training Loss: 1.711205 ; Training Acc: 22.701\n",
      "Iteration: 32 /1000;  Testing Loss: 2.070682 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 33 /1000;  Training Loss: 1.710953 ; Training Acc: 22.701\n",
      "Iteration: 33 /1000;  Testing Loss: 2.070085 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 34 /1000;  Training Loss: 1.710913 ; Training Acc: 22.701\n",
      "Iteration: 34 /1000;  Testing Loss: 2.069599 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 35 /1000;  Training Loss: 1.710923 ; Training Acc: 22.701\n",
      "Iteration: 35 /1000;  Testing Loss: 2.067702 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 36 /1000;  Training Loss: 1.710392 ; Training Acc: 22.701\n",
      "Iteration: 36 /1000;  Testing Loss: 2.067431 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 37 /1000;  Training Loss: 1.710340 ; Training Acc: 22.701\n",
      "Iteration: 37 /1000;  Testing Loss: 2.067397 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 38 /1000;  Training Loss: 1.710108 ; Training Acc: 22.701\n",
      "Iteration: 38 /1000;  Testing Loss: 2.066622 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 39 /1000;  Training Loss: 1.710059 ; Training Acc: 22.701\n",
      "Iteration: 39 /1000;  Testing Loss: 2.066332 ; Testing Acc: 23.308\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 40 /1000;  Training Loss: 1.709994 ; Training Acc: 22.701\n",
      "Iteration: 40 /1000;  Testing Loss: 2.065354 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 41 /1000;  Training Loss: 1.709880 ; Training Acc: 22.701\n",
      "Iteration: 41 /1000;  Testing Loss: 2.065413 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 42 /1000;  Training Loss: 1.709619 ; Training Acc: 22.701\n",
      "Iteration: 42 /1000;  Testing Loss: 2.062842 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 43 /1000;  Training Loss: 1.709489 ; Training Acc: 22.701\n",
      "Iteration: 43 /1000;  Testing Loss: 2.061479 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 44 /1000;  Training Loss: 1.709422 ; Training Acc: 22.701\n",
      "Iteration: 44 /1000;  Testing Loss: 2.062582 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 45 /1000;  Training Loss: 1.709304 ; Training Acc: 22.701\n",
      "Iteration: 45 /1000;  Testing Loss: 2.060559 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 46 /1000;  Training Loss: 1.709109 ; Training Acc: 22.701\n",
      "Iteration: 46 /1000;  Testing Loss: 2.060202 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 47 /1000;  Training Loss: 1.709028 ; Training Acc: 22.701\n",
      "Iteration: 47 /1000;  Testing Loss: 2.059327 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 48 /1000;  Training Loss: 1.709252 ; Training Acc: 22.701\n",
      "Iteration: 48 /1000;  Testing Loss: 2.061145 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 49 /1000;  Training Loss: 1.708749 ; Training Acc: 22.701\n",
      "Iteration: 49 /1000;  Testing Loss: 2.058072 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 50 /1000;  Training Loss: 1.708725 ; Training Acc: 22.701\n",
      "Iteration: 50 /1000;  Testing Loss: 2.055955 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 51 /1000;  Training Loss: 1.708744 ; Training Acc: 22.701\n",
      "Iteration: 51 /1000;  Testing Loss: 2.056543 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 52 /1000;  Training Loss: 1.708573 ; Training Acc: 22.701\n",
      "Iteration: 52 /1000;  Testing Loss: 2.055984 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 53 /1000;  Training Loss: 1.708619 ; Training Acc: 22.701\n",
      "Iteration: 53 /1000;  Testing Loss: 2.054542 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 54 /1000;  Training Loss: 1.708385 ; Training Acc: 22.701\n",
      "Iteration: 54 /1000;  Testing Loss: 2.053868 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 55 /1000;  Training Loss: 1.708405 ; Training Acc: 22.701\n",
      "Iteration: 55 /1000;  Testing Loss: 2.054877 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 56 /1000;  Training Loss: 1.708515 ; Training Acc: 22.701\n",
      "Iteration: 56 /1000;  Testing Loss: 2.055778 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 57 /1000;  Training Loss: 1.708593 ; Training Acc: 22.701\n",
      "Iteration: 57 /1000;  Testing Loss: 2.053783 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 58 /1000;  Training Loss: 1.708474 ; Training Acc: 22.701\n",
      "Iteration: 58 /1000;  Testing Loss: 2.057218 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 59 /1000;  Training Loss: 1.708190 ; Training Acc: 22.701\n",
      "Iteration: 59 /1000;  Testing Loss: 2.054694 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 60 /1000;  Training Loss: 1.708182 ; Training Acc: 22.701\n",
      "Iteration: 60 /1000;  Testing Loss: 2.053641 ; Testing Acc: 24.060\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 61 /1000;  Training Loss: 1.708287 ; Training Acc: 22.701\n",
      "Iteration: 61 /1000;  Testing Loss: 2.050461 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 62 /1000;  Training Loss: 1.707914 ; Training Acc: 22.701\n",
      "Iteration: 62 /1000;  Testing Loss: 2.053521 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 63 /1000;  Training Loss: 1.707921 ; Training Acc: 22.701\n",
      "Iteration: 63 /1000;  Testing Loss: 2.053174 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 64 /1000;  Training Loss: 1.708368 ; Training Acc: 22.701\n",
      "Iteration: 64 /1000;  Testing Loss: 2.056965 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 65 /1000;  Training Loss: 1.707625 ; Training Acc: 22.701\n",
      "Iteration: 65 /1000;  Testing Loss: 2.051123 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 66 /1000;  Training Loss: 1.707977 ; Training Acc: 22.701\n",
      "Iteration: 66 /1000;  Testing Loss: 2.052718 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 67 /1000;  Training Loss: 1.707674 ; Training Acc: 22.701\n",
      "Iteration: 67 /1000;  Testing Loss: 2.051896 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 68 /1000;  Training Loss: 1.707931 ; Training Acc: 22.701\n",
      "Iteration: 68 /1000;  Testing Loss: 2.052790 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 69 /1000;  Training Loss: 1.707614 ; Training Acc: 22.701\n",
      "Iteration: 69 /1000;  Testing Loss: 2.049235 ; Testing Acc: 24.060\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 70 /1000;  Training Loss: 1.707812 ; Training Acc: 22.701\n",
      "Iteration: 70 /1000;  Testing Loss: 2.049209 ; Testing Acc: 24.060\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 71 /1000;  Training Loss: 1.707154 ; Training Acc: 22.701\n",
      "Iteration: 71 /1000;  Testing Loss: 2.051897 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 72 /1000;  Training Loss: 1.707168 ; Training Acc: 22.701\n",
      "Iteration: 72 /1000;  Testing Loss: 2.050897 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 73 /1000;  Training Loss: 1.706688 ; Training Acc: 22.701\n",
      "Iteration: 73 /1000;  Testing Loss: 2.045604 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 74 /1000;  Training Loss: 1.707642 ; Training Acc: 22.701\n",
      "Iteration: 74 /1000;  Testing Loss: 2.061021 ; Testing Acc: 24.060\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 75 /1000;  Training Loss: 1.708255 ; Training Acc: 22.701\n",
      "Iteration: 75 /1000;  Testing Loss: 2.057847 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 76 /1000;  Training Loss: 1.707943 ; Training Acc: 22.701\n",
      "Iteration: 76 /1000;  Testing Loss: 2.056326 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 77 /1000;  Training Loss: 1.707866 ; Training Acc: 22.701\n",
      "Iteration: 77 /1000;  Testing Loss: 2.053818 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 78 /1000;  Training Loss: 1.707703 ; Training Acc: 22.701\n",
      "Iteration: 78 /1000;  Testing Loss: 2.053282 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 79 /1000;  Training Loss: 1.707640 ; Training Acc: 22.701\n",
      "Iteration: 79 /1000;  Testing Loss: 2.051763 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 80 /1000;  Training Loss: 1.707686 ; Training Acc: 22.701\n",
      "Iteration: 80 /1000;  Testing Loss: 2.052926 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 81 /1000;  Training Loss: 1.707610 ; Training Acc: 22.701\n",
      "Iteration: 81 /1000;  Testing Loss: 2.052391 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 82 /1000;  Training Loss: 1.707750 ; Training Acc: 22.701\n",
      "Iteration: 82 /1000;  Testing Loss: 2.047710 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 83 /1000;  Training Loss: 1.707731 ; Training Acc: 22.701\n",
      "Iteration: 83 /1000;  Testing Loss: 2.050923 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 84 /1000;  Training Loss: 1.707319 ; Training Acc: 22.701\n",
      "Iteration: 84 /1000;  Testing Loss: 2.049241 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 85 /1000;  Training Loss: 1.707293 ; Training Acc: 22.701\n",
      "Iteration: 85 /1000;  Testing Loss: 2.048903 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 86 /1000;  Training Loss: 1.707232 ; Training Acc: 22.701\n",
      "Iteration: 86 /1000;  Testing Loss: 2.050426 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 87 /1000;  Training Loss: 1.707218 ; Training Acc: 22.701\n",
      "Iteration: 87 /1000;  Testing Loss: 2.049491 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 88 /1000;  Training Loss: 1.707734 ; Training Acc: 22.701\n",
      "Iteration: 88 /1000;  Testing Loss: 2.046905 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 89 /1000;  Training Loss: 1.707312 ; Training Acc: 22.701\n",
      "Iteration: 89 /1000;  Testing Loss: 2.050914 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 90 /1000;  Training Loss: 1.707639 ; Training Acc: 23.092\n",
      "Iteration: 90 /1000;  Testing Loss: 2.052906 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 91 /1000;  Training Loss: 1.707249 ; Training Acc: 22.896\n",
      "Iteration: 91 /1000;  Testing Loss: 2.048447 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 92 /1000;  Training Loss: 1.707085 ; Training Acc: 22.701\n",
      "Iteration: 92 /1000;  Testing Loss: 2.046710 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 93 /1000;  Training Loss: 1.707080 ; Training Acc: 22.701\n",
      "Iteration: 93 /1000;  Testing Loss: 2.046879 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 94 /1000;  Training Loss: 1.707009 ; Training Acc: 22.701\n",
      "Iteration: 94 /1000;  Testing Loss: 2.048901 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 95 /1000;  Training Loss: 1.707457 ; Training Acc: 22.701\n",
      "Iteration: 95 /1000;  Testing Loss: 2.047465 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 96 /1000;  Training Loss: 1.707035 ; Training Acc: 22.701\n",
      "Iteration: 96 /1000;  Testing Loss: 2.049457 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 97 /1000;  Training Loss: 1.706917 ; Training Acc: 22.701\n",
      "Iteration: 97 /1000;  Testing Loss: 2.049142 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 98 /1000;  Training Loss: 1.707201 ; Training Acc: 22.701\n",
      "Iteration: 98 /1000;  Testing Loss: 2.048008 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 99 /1000;  Training Loss: 1.707028 ; Training Acc: 22.701\n",
      "Iteration: 99 /1000;  Testing Loss: 2.049390 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 100 /1000;  Training Loss: 1.707078 ; Training Acc: 23.483\n",
      "Iteration: 100 /1000;  Testing Loss: 2.050393 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 101 /1000;  Training Loss: 1.707161 ; Training Acc: 22.701\n",
      "Iteration: 101 /1000;  Testing Loss: 2.043817 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 102 /1000;  Training Loss: 1.706759 ; Training Acc: 22.701\n",
      "Iteration: 102 /1000;  Testing Loss: 2.044695 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 103 /1000;  Training Loss: 1.707071 ; Training Acc: 22.505\n",
      "Iteration: 103 /1000;  Testing Loss: 2.049637 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 104 /1000;  Training Loss: 1.706670 ; Training Acc: 24.462\n",
      "Iteration: 104 /1000;  Testing Loss: 2.048938 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 105 /1000;  Training Loss: 1.706592 ; Training Acc: 22.701\n",
      "Iteration: 105 /1000;  Testing Loss: 2.047072 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 106 /1000;  Training Loss: 1.706581 ; Training Acc: 22.701\n",
      "Iteration: 106 /1000;  Testing Loss: 2.045502 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 107 /1000;  Training Loss: 1.706914 ; Training Acc: 22.701\n",
      "Iteration: 107 /1000;  Testing Loss: 2.046088 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 108 /1000;  Training Loss: 1.706509 ; Training Acc: 22.896\n",
      "Iteration: 108 /1000;  Testing Loss: 2.048057 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 109 /1000;  Training Loss: 1.706534 ; Training Acc: 23.092\n",
      "Iteration: 109 /1000;  Testing Loss: 2.047553 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 110 /1000;  Training Loss: 1.706483 ; Training Acc: 25.636\n",
      "Iteration: 110 /1000;  Testing Loss: 2.048075 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 111 /1000;  Training Loss: 1.707026 ; Training Acc: 22.701\n",
      "Iteration: 111 /1000;  Testing Loss: 2.042384 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 112 /1000;  Training Loss: 1.706322 ; Training Acc: 22.701\n",
      "Iteration: 112 /1000;  Testing Loss: 2.045772 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 113 /1000;  Training Loss: 1.706300 ; Training Acc: 23.679\n",
      "Iteration: 113 /1000;  Testing Loss: 2.048603 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 114 /1000;  Training Loss: 1.706389 ; Training Acc: 24.658\n",
      "Iteration: 114 /1000;  Testing Loss: 2.046869 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 115 /1000;  Training Loss: 1.706221 ; Training Acc: 23.875\n",
      "Iteration: 115 /1000;  Testing Loss: 2.047262 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 116 /1000;  Training Loss: 1.706319 ; Training Acc: 24.266\n",
      "Iteration: 116 /1000;  Testing Loss: 2.046425 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 117 /1000;  Training Loss: 1.706097 ; Training Acc: 23.092\n",
      "Iteration: 117 /1000;  Testing Loss: 2.044219 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 118 /1000;  Training Loss: 1.706031 ; Training Acc: 22.896\n",
      "Iteration: 118 /1000;  Testing Loss: 2.045492 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 119 /1000;  Training Loss: 1.706095 ; Training Acc: 24.462\n",
      "Iteration: 119 /1000;  Testing Loss: 2.048440 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 120 /1000;  Training Loss: 1.706096 ; Training Acc: 24.853\n",
      "Iteration: 120 /1000;  Testing Loss: 2.045268 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 121 /1000;  Training Loss: 1.706228 ; Training Acc: 25.636\n",
      "Iteration: 121 /1000;  Testing Loss: 2.046124 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 122 /1000;  Training Loss: 1.706362 ; Training Acc: 23.288\n",
      "Iteration: 122 /1000;  Testing Loss: 2.043277 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 123 /1000;  Training Loss: 1.706075 ; Training Acc: 26.223\n",
      "Iteration: 123 /1000;  Testing Loss: 2.047622 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 124 /1000;  Training Loss: 1.706299 ; Training Acc: 22.896\n",
      "Iteration: 124 /1000;  Testing Loss: 2.043560 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 125 /1000;  Training Loss: 1.707164 ; Training Acc: 23.679\n",
      "Iteration: 125 /1000;  Testing Loss: 2.048077 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 126 /1000;  Training Loss: 1.705785 ; Training Acc: 23.679\n",
      "Iteration: 126 /1000;  Testing Loss: 2.043585 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 127 /1000;  Training Loss: 1.705908 ; Training Acc: 25.245\n",
      "Iteration: 127 /1000;  Testing Loss: 2.046439 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 128 /1000;  Training Loss: 1.705540 ; Training Acc: 25.049\n",
      "Iteration: 128 /1000;  Testing Loss: 2.042232 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 129 /1000;  Training Loss: 1.705445 ; Training Acc: 24.070\n",
      "Iteration: 129 /1000;  Testing Loss: 2.045905 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 130 /1000;  Training Loss: 1.705387 ; Training Acc: 26.419\n",
      "Iteration: 130 /1000;  Testing Loss: 2.044935 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 131 /1000;  Training Loss: 1.705233 ; Training Acc: 25.832\n",
      "Iteration: 131 /1000;  Testing Loss: 2.044330 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 132 /1000;  Training Loss: 1.705692 ; Training Acc: 26.810\n",
      "Iteration: 132 /1000;  Testing Loss: 2.048164 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 133 /1000;  Training Loss: 1.705025 ; Training Acc: 28.180\n",
      "Iteration: 133 /1000;  Testing Loss: 2.043768 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 134 /1000;  Training Loss: 1.705185 ; Training Acc: 25.636\n",
      "Iteration: 134 /1000;  Testing Loss: 2.044963 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 135 /1000;  Training Loss: 1.704862 ; Training Acc: 26.223\n",
      "Iteration: 135 /1000;  Testing Loss: 2.043309 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 136 /1000;  Training Loss: 1.705128 ; Training Acc: 25.440\n",
      "Iteration: 136 /1000;  Testing Loss: 2.045125 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 137 /1000;  Training Loss: 1.704931 ; Training Acc: 25.832\n",
      "Iteration: 137 /1000;  Testing Loss: 2.044267 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 138 /1000;  Training Loss: 1.704747 ; Training Acc: 26.614\n",
      "Iteration: 138 /1000;  Testing Loss: 2.044212 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 139 /1000;  Training Loss: 1.704792 ; Training Acc: 27.984\n",
      "Iteration: 139 /1000;  Testing Loss: 2.046122 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 140 /1000;  Training Loss: 1.704701 ; Training Acc: 28.767\n",
      "Iteration: 140 /1000;  Testing Loss: 2.047100 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 141 /1000;  Training Loss: 1.704588 ; Training Acc: 25.440\n",
      "Iteration: 141 /1000;  Testing Loss: 2.042026 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 142 /1000;  Training Loss: 1.704801 ; Training Acc: 27.006\n",
      "Iteration: 142 /1000;  Testing Loss: 2.048055 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 143 /1000;  Training Loss: 1.704862 ; Training Acc: 25.245\n",
      "Iteration: 143 /1000;  Testing Loss: 2.040386 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 144 /1000;  Training Loss: 1.705004 ; Training Acc: 27.984\n",
      "Iteration: 144 /1000;  Testing Loss: 2.043246 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 145 /1000;  Training Loss: 1.704329 ; Training Acc: 25.245\n",
      "Iteration: 145 /1000;  Testing Loss: 2.040879 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 146 /1000;  Training Loss: 1.703804 ; Training Acc: 28.376\n",
      "Iteration: 146 /1000;  Testing Loss: 2.047358 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 147 /1000;  Training Loss: 1.705251 ; Training Acc: 24.462\n",
      "Iteration: 147 /1000;  Testing Loss: 2.049727 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 148 /1000;  Training Loss: 1.703368 ; Training Acc: 26.810\n",
      "Iteration: 148 /1000;  Testing Loss: 2.039657 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 149 /1000;  Training Loss: 1.704003 ; Training Acc: 25.832\n",
      "Iteration: 149 /1000;  Testing Loss: 2.039086 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 150 /1000;  Training Loss: 1.704366 ; Training Acc: 23.288\n",
      "Iteration: 150 /1000;  Testing Loss: 2.038401 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 151 /1000;  Training Loss: 1.703387 ; Training Acc: 28.963\n",
      "Iteration: 151 /1000;  Testing Loss: 2.049567 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 152 /1000;  Training Loss: 1.703758 ; Training Acc: 27.202\n",
      "Iteration: 152 /1000;  Testing Loss: 2.041776 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 153 /1000;  Training Loss: 1.704478 ; Training Acc: 25.440\n",
      "Iteration: 153 /1000;  Testing Loss: 2.048288 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 154 /1000;  Training Loss: 1.702468 ; Training Acc: 29.354\n",
      "Iteration: 154 /1000;  Testing Loss: 2.039497 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 155 /1000;  Training Loss: 1.703079 ; Training Acc: 23.875\n",
      "Iteration: 155 /1000;  Testing Loss: 2.038266 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 156 /1000;  Training Loss: 1.703951 ; Training Acc: 24.658\n",
      "Iteration: 156 /1000;  Testing Loss: 2.050841 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 157 /1000;  Training Loss: 1.702860 ; Training Acc: 27.006\n",
      "Iteration: 157 /1000;  Testing Loss: 2.034962 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 158 /1000;  Training Loss: 1.703195 ; Training Acc: 25.832\n",
      "Iteration: 158 /1000;  Testing Loss: 2.046834 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 159 /1000;  Training Loss: 1.703000 ; Training Acc: 26.810\n",
      "Iteration: 159 /1000;  Testing Loss: 2.042499 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 160 /1000;  Training Loss: 1.702338 ; Training Acc: 29.354\n",
      "Iteration: 160 /1000;  Testing Loss: 2.040581 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 161 /1000;  Training Loss: 1.701539 ; Training Acc: 27.397\n",
      "Iteration: 161 /1000;  Testing Loss: 2.041938 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 162 /1000;  Training Loss: 1.701252 ; Training Acc: 30.333\n",
      "Iteration: 162 /1000;  Testing Loss: 2.042893 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 163 /1000;  Training Loss: 1.701826 ; Training Acc: 28.376\n",
      "Iteration: 163 /1000;  Testing Loss: 2.044031 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 164 /1000;  Training Loss: 1.700885 ; Training Acc: 30.920\n",
      "Iteration: 164 /1000;  Testing Loss: 2.046591 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 165 /1000;  Training Loss: 1.701282 ; Training Acc: 24.462\n",
      "Iteration: 165 /1000;  Testing Loss: 2.038186 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 166 /1000;  Training Loss: 1.701147 ; Training Acc: 23.875\n",
      "Iteration: 166 /1000;  Testing Loss: 2.034264 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 167 /1000;  Training Loss: 1.700495 ; Training Acc: 29.354\n",
      "Iteration: 167 /1000;  Testing Loss: 2.043850 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 168 /1000;  Training Loss: 1.700665 ; Training Acc: 29.354\n",
      "Iteration: 168 /1000;  Testing Loss: 2.037876 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 169 /1000;  Training Loss: 1.700281 ; Training Acc: 27.789\n",
      "Iteration: 169 /1000;  Testing Loss: 2.043398 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 170 /1000;  Training Loss: 1.699168 ; Training Acc: 28.767\n",
      "Iteration: 170 /1000;  Testing Loss: 2.033747 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 171 /1000;  Training Loss: 1.698981 ; Training Acc: 30.137\n",
      "Iteration: 171 /1000;  Testing Loss: 2.038960 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 172 /1000;  Training Loss: 1.698500 ; Training Acc: 27.397\n",
      "Iteration: 172 /1000;  Testing Loss: 2.032951 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 173 /1000;  Training Loss: 1.698271 ; Training Acc: 29.941\n",
      "Iteration: 173 /1000;  Testing Loss: 2.046973 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 174 /1000;  Training Loss: 1.697557 ; Training Acc: 27.006\n",
      "Iteration: 174 /1000;  Testing Loss: 2.039788 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 175 /1000;  Training Loss: 1.696717 ; Training Acc: 28.767\n",
      "Iteration: 175 /1000;  Testing Loss: 2.036873 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 176 /1000;  Training Loss: 1.695386 ; Training Acc: 28.376\n",
      "Iteration: 176 /1000;  Testing Loss: 2.039073 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 177 /1000;  Training Loss: 1.694505 ; Training Acc: 31.898\n",
      "Iteration: 177 /1000;  Testing Loss: 2.032671 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 178 /1000;  Training Loss: 1.693273 ; Training Acc: 30.920\n",
      "Iteration: 178 /1000;  Testing Loss: 2.034816 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 179 /1000;  Training Loss: 1.691840 ; Training Acc: 32.094\n",
      "Iteration: 179 /1000;  Testing Loss: 2.031024 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 180 /1000;  Training Loss: 1.689047 ; Training Acc: 31.507\n",
      "Iteration: 180 /1000;  Testing Loss: 2.032465 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 181 /1000;  Training Loss: 1.688540 ; Training Acc: 32.094\n",
      "Iteration: 181 /1000;  Testing Loss: 2.017526 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 182 /1000;  Training Loss: 1.685446 ; Training Acc: 29.159\n",
      "Iteration: 182 /1000;  Testing Loss: 2.047571 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 183 /1000;  Training Loss: 1.682066 ; Training Acc: 32.681\n",
      "Iteration: 183 /1000;  Testing Loss: 2.019480 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 184 /1000;  Training Loss: 1.686136 ; Training Acc: 24.070\n",
      "Iteration: 184 /1000;  Testing Loss: 2.010521 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 185 /1000;  Training Loss: 1.687612 ; Training Acc: 27.202\n",
      "Iteration: 185 /1000;  Testing Loss: 2.006621 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 186 /1000;  Training Loss: 1.693742 ; Training Acc: 23.875\n",
      "Iteration: 186 /1000;  Testing Loss: 2.007311 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 187 /1000;  Training Loss: 1.674072 ; Training Acc: 30.528\n",
      "Iteration: 187 /1000;  Testing Loss: 2.007075 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 188 /1000;  Training Loss: 1.682106 ; Training Acc: 26.223\n",
      "Iteration: 188 /1000;  Testing Loss: 2.022082 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 189 /1000;  Training Loss: 1.687812 ; Training Acc: 25.440\n",
      "Iteration: 189 /1000;  Testing Loss: 2.003323 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 190 /1000;  Training Loss: 1.683522 ; Training Acc: 26.810\n",
      "Iteration: 190 /1000;  Testing Loss: 2.031526 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 191 /1000;  Training Loss: 1.658055 ; Training Acc: 35.225\n",
      "Iteration: 191 /1000;  Testing Loss: 2.038975 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 192 /1000;  Training Loss: 1.654205 ; Training Acc: 30.920\n",
      "Iteration: 192 /1000;  Testing Loss: 2.003668 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 193 /1000;  Training Loss: 1.649049 ; Training Acc: 29.941\n",
      "Iteration: 193 /1000;  Testing Loss: 2.024578 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 194 /1000;  Training Loss: 1.672907 ; Training Acc: 27.202\n",
      "Iteration: 194 /1000;  Testing Loss: 1.989260 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 195 /1000;  Training Loss: 1.647940 ; Training Acc: 31.115\n",
      "Iteration: 195 /1000;  Testing Loss: 2.044882 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 196 /1000;  Training Loss: 1.634011 ; Training Acc: 31.703\n",
      "Iteration: 196 /1000;  Testing Loss: 2.000266 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 197 /1000;  Training Loss: 1.618428 ; Training Acc: 33.855\n",
      "Iteration: 197 /1000;  Testing Loss: 2.019680 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 198 /1000;  Training Loss: 1.630252 ; Training Acc: 32.681\n",
      "Iteration: 198 /1000;  Testing Loss: 2.011367 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 199 /1000;  Training Loss: 1.628844 ; Training Acc: 33.464\n",
      "Iteration: 199 /1000;  Testing Loss: 1.980153 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 200 /1000;  Training Loss: 1.685417 ; Training Acc: 24.266\n",
      "Iteration: 200 /1000;  Testing Loss: 1.999809 ; Testing Acc: 17.293\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 201 /1000;  Training Loss: 1.635600 ; Training Acc: 31.115\n",
      "Iteration: 201 /1000;  Testing Loss: 2.051718 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 202 /1000;  Training Loss: 1.603755 ; Training Acc: 38.356\n",
      "Iteration: 202 /1000;  Testing Loss: 1.989079 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 203 /1000;  Training Loss: 1.599395 ; Training Acc: 37.378\n",
      "Iteration: 203 /1000;  Testing Loss: 1.972367 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 204 /1000;  Training Loss: 1.648653 ; Training Acc: 27.984\n",
      "Iteration: 204 /1000;  Testing Loss: 2.148729 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 205 /1000;  Training Loss: 1.732238 ; Training Acc: 22.896\n",
      "Iteration: 205 /1000;  Testing Loss: 1.974636 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 206 /1000;  Training Loss: 1.618163 ; Training Acc: 33.659\n",
      "Iteration: 206 /1000;  Testing Loss: 1.991741 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 207 /1000;  Training Loss: 1.634345 ; Training Acc: 30.528\n",
      "Iteration: 207 /1000;  Testing Loss: 1.969561 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 208 /1000;  Training Loss: 1.675815 ; Training Acc: 27.984\n",
      "Iteration: 208 /1000;  Testing Loss: 1.970997 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 209 /1000;  Training Loss: 1.593016 ; Training Acc: 38.160\n",
      "Iteration: 209 /1000;  Testing Loss: 1.972593 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 210 /1000;  Training Loss: 1.597422 ; Training Acc: 36.595\n",
      "Iteration: 210 /1000;  Testing Loss: 1.995807 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 211 /1000;  Training Loss: 1.593318 ; Training Acc: 37.182\n",
      "Iteration: 211 /1000;  Testing Loss: 1.997673 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 212 /1000;  Training Loss: 1.614476 ; Training Acc: 32.485\n",
      "Iteration: 212 /1000;  Testing Loss: 1.967447 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 213 /1000;  Training Loss: 1.595777 ; Training Acc: 35.225\n",
      "Iteration: 213 /1000;  Testing Loss: 1.966113 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 214 /1000;  Training Loss: 1.593802 ; Training Acc: 34.247\n",
      "Iteration: 214 /1000;  Testing Loss: 1.986485 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 215 /1000;  Training Loss: 1.600058 ; Training Acc: 32.877\n",
      "Iteration: 215 /1000;  Testing Loss: 1.999953 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 216 /1000;  Training Loss: 1.573354 ; Training Acc: 36.204\n",
      "Iteration: 216 /1000;  Testing Loss: 1.968238 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 217 /1000;  Training Loss: 1.582611 ; Training Acc: 35.421\n",
      "Iteration: 217 /1000;  Testing Loss: 1.972914 ; Testing Acc: 22.556\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 218 /1000;  Training Loss: 1.581830 ; Training Acc: 33.855\n",
      "Iteration: 218 /1000;  Testing Loss: 1.962149 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 219 /1000;  Training Loss: 1.563209 ; Training Acc: 38.943\n",
      "Iteration: 219 /1000;  Testing Loss: 1.979279 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 220 /1000;  Training Loss: 1.587840 ; Training Acc: 36.204\n",
      "Iteration: 220 /1000;  Testing Loss: 1.960675 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 221 /1000;  Training Loss: 1.585146 ; Training Acc: 32.681\n",
      "Iteration: 221 /1000;  Testing Loss: 2.075440 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 222 /1000;  Training Loss: 1.595015 ; Training Acc: 32.681\n",
      "Iteration: 222 /1000;  Testing Loss: 1.961553 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 223 /1000;  Training Loss: 1.572072 ; Training Acc: 36.595\n",
      "Iteration: 223 /1000;  Testing Loss: 1.998415 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 224 /1000;  Training Loss: 1.557606 ; Training Acc: 37.769\n",
      "Iteration: 224 /1000;  Testing Loss: 1.953507 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 225 /1000;  Training Loss: 1.554740 ; Training Acc: 38.552\n",
      "Iteration: 225 /1000;  Testing Loss: 1.950282 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 226 /1000;  Training Loss: 1.560276 ; Training Acc: 36.399\n",
      "Iteration: 226 /1000;  Testing Loss: 1.964122 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 227 /1000;  Training Loss: 1.590337 ; Training Acc: 33.659\n",
      "Iteration: 227 /1000;  Testing Loss: 1.983820 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 228 /1000;  Training Loss: 1.566947 ; Training Acc: 35.225\n",
      "Iteration: 228 /1000;  Testing Loss: 1.957328 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 229 /1000;  Training Loss: 1.555008 ; Training Acc: 36.986\n",
      "Iteration: 229 /1000;  Testing Loss: 1.955302 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 230 /1000;  Training Loss: 1.559527 ; Training Acc: 35.812\n",
      "Iteration: 230 /1000;  Testing Loss: 1.944741 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 231 /1000;  Training Loss: 1.549581 ; Training Acc: 36.791\n",
      "Iteration: 231 /1000;  Testing Loss: 1.965814 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 232 /1000;  Training Loss: 1.544061 ; Training Acc: 36.204\n",
      "Iteration: 232 /1000;  Testing Loss: 1.942877 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 233 /1000;  Training Loss: 1.544970 ; Training Acc: 36.008\n",
      "Iteration: 233 /1000;  Testing Loss: 1.947494 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 234 /1000;  Training Loss: 1.602211 ; Training Acc: 33.464\n",
      "Iteration: 234 /1000;  Testing Loss: 1.954153 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 235 /1000;  Training Loss: 1.548968 ; Training Acc: 36.008\n",
      "Iteration: 235 /1000;  Testing Loss: 1.951354 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 236 /1000;  Training Loss: 1.544891 ; Training Acc: 37.182\n",
      "Iteration: 236 /1000;  Testing Loss: 1.952234 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 237 /1000;  Training Loss: 1.553001 ; Training Acc: 36.008\n",
      "Iteration: 237 /1000;  Testing Loss: 1.953856 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 238 /1000;  Training Loss: 1.591564 ; Training Acc: 33.464\n",
      "Iteration: 238 /1000;  Testing Loss: 2.088558 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 239 /1000;  Training Loss: 1.567692 ; Training Acc: 36.008\n",
      "Iteration: 239 /1000;  Testing Loss: 1.942057 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 240 /1000;  Training Loss: 1.535174 ; Training Acc: 37.182\n",
      "Iteration: 240 /1000;  Testing Loss: 1.955188 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 241 /1000;  Training Loss: 1.565046 ; Training Acc: 36.595\n",
      "Iteration: 241 /1000;  Testing Loss: 1.939413 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 242 /1000;  Training Loss: 1.533024 ; Training Acc: 37.378\n",
      "Iteration: 242 /1000;  Testing Loss: 1.942869 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 243 /1000;  Training Loss: 1.562952 ; Training Acc: 34.638\n",
      "Iteration: 243 /1000;  Testing Loss: 1.937831 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 244 /1000;  Training Loss: 1.529460 ; Training Acc: 36.986\n",
      "Iteration: 244 /1000;  Testing Loss: 2.000032 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 245 /1000;  Training Loss: 1.535953 ; Training Acc: 36.986\n",
      "Iteration: 245 /1000;  Testing Loss: 1.952787 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 246 /1000;  Training Loss: 1.561315 ; Training Acc: 36.008\n",
      "Iteration: 246 /1000;  Testing Loss: 1.941467 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 247 /1000;  Training Loss: 1.537462 ; Training Acc: 35.812\n",
      "Iteration: 247 /1000;  Testing Loss: 1.934599 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 248 /1000;  Training Loss: 1.556348 ; Training Acc: 34.247\n",
      "Iteration: 248 /1000;  Testing Loss: 1.945643 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 249 /1000;  Training Loss: 1.571155 ; Training Acc: 34.247\n",
      "Iteration: 249 /1000;  Testing Loss: 1.949169 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 250 /1000;  Training Loss: 1.555928 ; Training Acc: 34.638\n",
      "Iteration: 250 /1000;  Testing Loss: 1.960522 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 251 /1000;  Training Loss: 1.554951 ; Training Acc: 34.442\n",
      "Iteration: 251 /1000;  Testing Loss: 1.946078 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 252 /1000;  Training Loss: 1.518561 ; Training Acc: 37.965\n",
      "Iteration: 252 /1000;  Testing Loss: 1.933221 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 253 /1000;  Training Loss: 1.521217 ; Training Acc: 37.182\n",
      "Iteration: 253 /1000;  Testing Loss: 1.944921 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 254 /1000;  Training Loss: 1.582652 ; Training Acc: 31.898\n",
      "Iteration: 254 /1000;  Testing Loss: 1.935441 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 255 /1000;  Training Loss: 1.551973 ; Training Acc: 34.442\n",
      "Iteration: 255 /1000;  Testing Loss: 1.944373 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 256 /1000;  Training Loss: 1.532167 ; Training Acc: 37.378\n",
      "Iteration: 256 /1000;  Testing Loss: 1.975187 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 257 /1000;  Training Loss: 1.529465 ; Training Acc: 36.986\n",
      "Iteration: 257 /1000;  Testing Loss: 1.930246 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 258 /1000;  Training Loss: 1.540148 ; Training Acc: 34.638\n",
      "Iteration: 258 /1000;  Testing Loss: 2.018520 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 259 /1000;  Training Loss: 1.533811 ; Training Acc: 36.399\n",
      "Iteration: 259 /1000;  Testing Loss: 1.946166 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 260 /1000;  Training Loss: 1.533583 ; Training Acc: 36.791\n",
      "Iteration: 260 /1000;  Testing Loss: 1.928235 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 261 /1000;  Training Loss: 1.526090 ; Training Acc: 37.182\n",
      "Iteration: 261 /1000;  Testing Loss: 2.013220 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 262 /1000;  Training Loss: 1.605070 ; Training Acc: 30.920\n",
      "Iteration: 262 /1000;  Testing Loss: 1.991535 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 263 /1000;  Training Loss: 1.529721 ; Training Acc: 37.378\n",
      "Iteration: 263 /1000;  Testing Loss: 1.932432 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 264 /1000;  Training Loss: 1.523128 ; Training Acc: 39.139\n",
      "Iteration: 264 /1000;  Testing Loss: 1.932684 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 265 /1000;  Training Loss: 1.557155 ; Training Acc: 35.421\n",
      "Iteration: 265 /1000;  Testing Loss: 2.160567 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 266 /1000;  Training Loss: 1.561893 ; Training Acc: 31.898\n",
      "Iteration: 266 /1000;  Testing Loss: 1.934814 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 267 /1000;  Training Loss: 1.515344 ; Training Acc: 37.769\n",
      "Iteration: 267 /1000;  Testing Loss: 1.935269 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 268 /1000;  Training Loss: 1.512091 ; Training Acc: 38.160\n",
      "Iteration: 268 /1000;  Testing Loss: 1.953665 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 269 /1000;  Training Loss: 1.523710 ; Training Acc: 37.378\n",
      "Iteration: 269 /1000;  Testing Loss: 1.935992 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 270 /1000;  Training Loss: 1.515179 ; Training Acc: 37.182\n",
      "Iteration: 270 /1000;  Testing Loss: 2.045617 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 271 /1000;  Training Loss: 1.545582 ; Training Acc: 36.595\n",
      "Iteration: 271 /1000;  Testing Loss: 1.944945 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 272 /1000;  Training Loss: 1.523585 ; Training Acc: 37.769\n",
      "Iteration: 272 /1000;  Testing Loss: 1.936698 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 273 /1000;  Training Loss: 1.533796 ; Training Acc: 37.182\n",
      "Iteration: 273 /1000;  Testing Loss: 2.002623 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 274 /1000;  Training Loss: 1.533611 ; Training Acc: 37.378\n",
      "Iteration: 274 /1000;  Testing Loss: 1.925837 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 275 /1000;  Training Loss: 1.515384 ; Training Acc: 37.573\n",
      "Iteration: 275 /1000;  Testing Loss: 1.933461 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 276 /1000;  Training Loss: 1.514933 ; Training Acc: 37.573\n",
      "Iteration: 276 /1000;  Testing Loss: 1.947101 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 277 /1000;  Training Loss: 1.547710 ; Training Acc: 34.834\n",
      "Iteration: 277 /1000;  Testing Loss: 1.926591 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 278 /1000;  Training Loss: 1.503813 ; Training Acc: 37.573\n",
      "Iteration: 278 /1000;  Testing Loss: 1.924540 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 279 /1000;  Training Loss: 1.492110 ; Training Acc: 40.117\n",
      "Iteration: 279 /1000;  Testing Loss: 1.923196 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 280 /1000;  Training Loss: 1.496977 ; Training Acc: 38.552\n",
      "Iteration: 280 /1000;  Testing Loss: 1.930160 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 281 /1000;  Training Loss: 1.512151 ; Training Acc: 37.182\n",
      "Iteration: 281 /1000;  Testing Loss: 1.942807 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 282 /1000;  Training Loss: 1.540496 ; Training Acc: 34.638\n",
      "Iteration: 282 /1000;  Testing Loss: 1.937840 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 283 /1000;  Training Loss: 1.556519 ; Training Acc: 33.072\n",
      "Iteration: 283 /1000;  Testing Loss: 1.921775 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 284 /1000;  Training Loss: 1.535478 ; Training Acc: 35.029\n",
      "Iteration: 284 /1000;  Testing Loss: 1.918304 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 285 /1000;  Training Loss: 1.509679 ; Training Acc: 38.356\n",
      "Iteration: 285 /1000;  Testing Loss: 1.920021 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 286 /1000;  Training Loss: 1.522633 ; Training Acc: 39.335\n",
      "Iteration: 286 /1000;  Testing Loss: 1.916990 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 287 /1000;  Training Loss: 1.501059 ; Training Acc: 38.748\n",
      "Iteration: 287 /1000;  Testing Loss: 1.923479 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 288 /1000;  Training Loss: 1.494354 ; Training Acc: 39.726\n",
      "Iteration: 288 /1000;  Testing Loss: 1.916648 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 289 /1000;  Training Loss: 1.499972 ; Training Acc: 37.769\n",
      "Iteration: 289 /1000;  Testing Loss: 1.922227 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 290 /1000;  Training Loss: 1.495697 ; Training Acc: 38.552\n",
      "Iteration: 290 /1000;  Testing Loss: 1.923584 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 291 /1000;  Training Loss: 1.483952 ; Training Acc: 39.530\n",
      "Iteration: 291 /1000;  Testing Loss: 1.917096 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 292 /1000;  Training Loss: 1.483489 ; Training Acc: 40.313\n",
      "Iteration: 292 /1000;  Testing Loss: 1.934572 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 293 /1000;  Training Loss: 1.512770 ; Training Acc: 36.399\n",
      "Iteration: 293 /1000;  Testing Loss: 1.914897 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 294 /1000;  Training Loss: 1.495147 ; Training Acc: 38.160\n",
      "Iteration: 294 /1000;  Testing Loss: 1.924237 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 295 /1000;  Training Loss: 1.491110 ; Training Acc: 36.986\n",
      "Iteration: 295 /1000;  Testing Loss: 1.918621 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 296 /1000;  Training Loss: 1.491213 ; Training Acc: 39.335\n",
      "Iteration: 296 /1000;  Testing Loss: 1.912999 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 297 /1000;  Training Loss: 1.483563 ; Training Acc: 39.335\n",
      "Iteration: 297 /1000;  Testing Loss: 1.916030 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 298 /1000;  Training Loss: 1.480830 ; Training Acc: 39.530\n",
      "Iteration: 298 /1000;  Testing Loss: 1.911480 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 299 /1000;  Training Loss: 1.473521 ; Training Acc: 40.900\n",
      "Iteration: 299 /1000;  Testing Loss: 1.919330 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 300 /1000;  Training Loss: 1.531813 ; Training Acc: 37.378\n",
      "Iteration: 300 /1000;  Testing Loss: 1.910654 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 301 /1000;  Training Loss: 1.498000 ; Training Acc: 37.573\n",
      "Iteration: 301 /1000;  Testing Loss: 1.910217 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 302 /1000;  Training Loss: 1.487021 ; Training Acc: 39.726\n",
      "Iteration: 302 /1000;  Testing Loss: 1.914145 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 303 /1000;  Training Loss: 1.479531 ; Training Acc: 39.922\n",
      "Iteration: 303 /1000;  Testing Loss: 1.933998 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 304 /1000;  Training Loss: 1.486069 ; Training Acc: 40.313\n",
      "Iteration: 304 /1000;  Testing Loss: 1.919251 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 305 /1000;  Training Loss: 1.522669 ; Training Acc: 35.616\n",
      "Iteration: 305 /1000;  Testing Loss: 1.929360 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 306 /1000;  Training Loss: 1.474088 ; Training Acc: 37.182\n",
      "Iteration: 306 /1000;  Testing Loss: 1.917236 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 307 /1000;  Training Loss: 1.482005 ; Training Acc: 38.356\n",
      "Iteration: 307 /1000;  Testing Loss: 1.960135 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 308 /1000;  Training Loss: 1.488460 ; Training Acc: 40.705\n",
      "Iteration: 308 /1000;  Testing Loss: 1.918911 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 309 /1000;  Training Loss: 1.498293 ; Training Acc: 38.943\n",
      "Iteration: 309 /1000;  Testing Loss: 1.942340 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 310 /1000;  Training Loss: 1.476801 ; Training Acc: 37.573\n",
      "Iteration: 310 /1000;  Testing Loss: 1.905783 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 311 /1000;  Training Loss: 1.473504 ; Training Acc: 40.313\n",
      "Iteration: 311 /1000;  Testing Loss: 1.909688 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 312 /1000;  Training Loss: 1.464405 ; Training Acc: 40.509\n",
      "Iteration: 312 /1000;  Testing Loss: 1.955496 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 313 /1000;  Training Loss: 1.505518 ; Training Acc: 35.616\n",
      "Iteration: 313 /1000;  Testing Loss: 1.919835 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 314 /1000;  Training Loss: 1.522422 ; Training Acc: 34.638\n",
      "Iteration: 314 /1000;  Testing Loss: 1.910509 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 315 /1000;  Training Loss: 1.476315 ; Training Acc: 38.748\n",
      "Iteration: 315 /1000;  Testing Loss: 1.908575 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 316 /1000;  Training Loss: 1.468094 ; Training Acc: 38.943\n",
      "Iteration: 316 /1000;  Testing Loss: 1.909676 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 317 /1000;  Training Loss: 1.474919 ; Training Acc: 40.509\n",
      "Iteration: 317 /1000;  Testing Loss: 1.907160 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 318 /1000;  Training Loss: 1.474093 ; Training Acc: 40.705\n",
      "Iteration: 318 /1000;  Testing Loss: 1.914222 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 319 /1000;  Training Loss: 1.465250 ; Training Acc: 39.335\n",
      "Iteration: 319 /1000;  Testing Loss: 1.908433 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 320 /1000;  Training Loss: 1.497578 ; Training Acc: 35.225\n",
      "Iteration: 320 /1000;  Testing Loss: 1.908488 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 321 /1000;  Training Loss: 1.466351 ; Training Acc: 39.922\n",
      "Iteration: 321 /1000;  Testing Loss: 1.904378 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 322 /1000;  Training Loss: 1.492705 ; Training Acc: 40.117\n",
      "Iteration: 322 /1000;  Testing Loss: 1.934454 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 323 /1000;  Training Loss: 1.473637 ; Training Acc: 39.139\n",
      "Iteration: 323 /1000;  Testing Loss: 1.910099 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 324 /1000;  Training Loss: 1.473398 ; Training Acc: 39.530\n",
      "Iteration: 324 /1000;  Testing Loss: 1.913625 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 325 /1000;  Training Loss: 1.457279 ; Training Acc: 40.509\n",
      "Iteration: 325 /1000;  Testing Loss: 1.915746 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 326 /1000;  Training Loss: 1.459971 ; Training Acc: 41.292\n",
      "Iteration: 326 /1000;  Testing Loss: 1.910092 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 327 /1000;  Training Loss: 1.520561 ; Training Acc: 35.225\n",
      "Iteration: 327 /1000;  Testing Loss: 1.956737 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 328 /1000;  Training Loss: 1.598883 ; Training Acc: 31.898\n",
      "Iteration: 328 /1000;  Testing Loss: 1.943161 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 329 /1000;  Training Loss: 1.459521 ; Training Acc: 39.922\n",
      "Iteration: 329 /1000;  Testing Loss: 1.901884 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 330 /1000;  Training Loss: 1.497791 ; Training Acc: 37.965\n",
      "Iteration: 330 /1000;  Testing Loss: 1.917491 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 331 /1000;  Training Loss: 1.575738 ; Training Acc: 33.268\n",
      "Iteration: 331 /1000;  Testing Loss: 1.893366 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 332 /1000;  Training Loss: 1.523605 ; Training Acc: 35.616\n",
      "Iteration: 332 /1000;  Testing Loss: 1.898739 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 333 /1000;  Training Loss: 1.512590 ; Training Acc: 37.965\n",
      "Iteration: 333 /1000;  Testing Loss: 2.058538 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 334 /1000;  Training Loss: 1.558284 ; Training Acc: 36.008\n",
      "Iteration: 334 /1000;  Testing Loss: 1.988689 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 335 /1000;  Training Loss: 1.569706 ; Training Acc: 33.072\n",
      "Iteration: 335 /1000;  Testing Loss: 1.912576 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 336 /1000;  Training Loss: 1.499655 ; Training Acc: 38.356\n",
      "Iteration: 336 /1000;  Testing Loss: 1.887245 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 337 /1000;  Training Loss: 1.459729 ; Training Acc: 41.292\n",
      "Iteration: 337 /1000;  Testing Loss: 1.914919 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 338 /1000;  Training Loss: 1.466005 ; Training Acc: 40.509\n",
      "Iteration: 338 /1000;  Testing Loss: 1.892846 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 339 /1000;  Training Loss: 1.453362 ; Training Acc: 41.096\n",
      "Iteration: 339 /1000;  Testing Loss: 1.898582 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 340 /1000;  Training Loss: 1.450429 ; Training Acc: 41.683\n",
      "Iteration: 340 /1000;  Testing Loss: 1.924806 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 341 /1000;  Training Loss: 1.492991 ; Training Acc: 38.160\n",
      "Iteration: 341 /1000;  Testing Loss: 1.907288 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 342 /1000;  Training Loss: 1.470882 ; Training Acc: 41.487\n",
      "Iteration: 342 /1000;  Testing Loss: 1.893278 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 343 /1000;  Training Loss: 1.458128 ; Training Acc: 39.922\n",
      "Iteration: 343 /1000;  Testing Loss: 1.907859 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 344 /1000;  Training Loss: 1.457642 ; Training Acc: 39.335\n",
      "Iteration: 344 /1000;  Testing Loss: 1.933746 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 345 /1000;  Training Loss: 1.450339 ; Training Acc: 41.292\n",
      "Iteration: 345 /1000;  Testing Loss: 1.908771 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 346 /1000;  Training Loss: 1.446408 ; Training Acc: 40.509\n",
      "Iteration: 346 /1000;  Testing Loss: 1.904094 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 347 /1000;  Training Loss: 1.451548 ; Training Acc: 39.530\n",
      "Iteration: 347 /1000;  Testing Loss: 1.895682 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 348 /1000;  Training Loss: 1.453146 ; Training Acc: 40.705\n",
      "Iteration: 348 /1000;  Testing Loss: 1.897672 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 349 /1000;  Training Loss: 1.451725 ; Training Acc: 40.705\n",
      "Iteration: 349 /1000;  Testing Loss: 1.923770 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 350 /1000;  Training Loss: 1.477058 ; Training Acc: 37.573\n",
      "Iteration: 350 /1000;  Testing Loss: 1.895143 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 351 /1000;  Training Loss: 1.518212 ; Training Acc: 35.029\n",
      "Iteration: 351 /1000;  Testing Loss: 1.888825 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 352 /1000;  Training Loss: 1.472172 ; Training Acc: 40.117\n",
      "Iteration: 352 /1000;  Testing Loss: 1.900927 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 353 /1000;  Training Loss: 1.447411 ; Training Acc: 40.509\n",
      "Iteration: 353 /1000;  Testing Loss: 1.889020 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 354 /1000;  Training Loss: 1.447464 ; Training Acc: 39.922\n",
      "Iteration: 354 /1000;  Testing Loss: 1.896926 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 355 /1000;  Training Loss: 1.451049 ; Training Acc: 40.509\n",
      "Iteration: 355 /1000;  Testing Loss: 1.939669 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 356 /1000;  Training Loss: 1.480737 ; Training Acc: 37.573\n",
      "Iteration: 356 /1000;  Testing Loss: 1.887438 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 357 /1000;  Training Loss: 1.481636 ; Training Acc: 38.356\n",
      "Iteration: 357 /1000;  Testing Loss: 1.888714 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 358 /1000;  Training Loss: 1.472391 ; Training Acc: 37.769\n",
      "Iteration: 358 /1000;  Testing Loss: 1.906905 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 359 /1000;  Training Loss: 1.440924 ; Training Acc: 40.705\n",
      "Iteration: 359 /1000;  Testing Loss: 1.880447 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 360 /1000;  Training Loss: 1.441476 ; Training Acc: 41.096\n",
      "Iteration: 360 /1000;  Testing Loss: 1.887919 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 361 /1000;  Training Loss: 1.443651 ; Training Acc: 41.487\n",
      "Iteration: 361 /1000;  Testing Loss: 1.886986 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 362 /1000;  Training Loss: 1.465804 ; Training Acc: 39.726\n",
      "Iteration: 362 /1000;  Testing Loss: 1.894014 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 363 /1000;  Training Loss: 1.441416 ; Training Acc: 40.313\n",
      "Iteration: 363 /1000;  Testing Loss: 1.882652 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 364 /1000;  Training Loss: 1.452320 ; Training Acc: 40.509\n",
      "Iteration: 364 /1000;  Testing Loss: 1.884985 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 365 /1000;  Training Loss: 1.432832 ; Training Acc: 40.900\n",
      "Iteration: 365 /1000;  Testing Loss: 1.907852 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 366 /1000;  Training Loss: 1.424951 ; Training Acc: 41.487\n",
      "Iteration: 366 /1000;  Testing Loss: 1.918527 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 367 /1000;  Training Loss: 1.441629 ; Training Acc: 41.683\n",
      "Iteration: 367 /1000;  Testing Loss: 1.876801 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 368 /1000;  Training Loss: 1.465443 ; Training Acc: 41.487\n",
      "Iteration: 368 /1000;  Testing Loss: 1.922857 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 369 /1000;  Training Loss: 1.464890 ; Training Acc: 38.943\n",
      "Iteration: 369 /1000;  Testing Loss: 1.904650 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 370 /1000;  Training Loss: 1.433443 ; Training Acc: 42.270\n",
      "Iteration: 370 /1000;  Testing Loss: 1.899971 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 371 /1000;  Training Loss: 1.473477 ; Training Acc: 38.943\n",
      "Iteration: 371 /1000;  Testing Loss: 1.936288 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 372 /1000;  Training Loss: 1.487084 ; Training Acc: 36.399\n",
      "Iteration: 372 /1000;  Testing Loss: 1.888560 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 373 /1000;  Training Loss: 1.442591 ; Training Acc: 41.292\n",
      "Iteration: 373 /1000;  Testing Loss: 1.881350 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 374 /1000;  Training Loss: 1.431640 ; Training Acc: 40.900\n",
      "Iteration: 374 /1000;  Testing Loss: 1.905014 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 375 /1000;  Training Loss: 1.442080 ; Training Acc: 41.683\n",
      "Iteration: 375 /1000;  Testing Loss: 1.876816 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 376 /1000;  Training Loss: 1.442908 ; Training Acc: 40.900\n",
      "Iteration: 376 /1000;  Testing Loss: 1.891602 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 377 /1000;  Training Loss: 1.419254 ; Training Acc: 43.249\n",
      "Iteration: 377 /1000;  Testing Loss: 1.878982 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 378 /1000;  Training Loss: 1.450964 ; Training Acc: 41.292\n",
      "Iteration: 378 /1000;  Testing Loss: 1.947230 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 379 /1000;  Training Loss: 1.435835 ; Training Acc: 40.900\n",
      "Iteration: 379 /1000;  Testing Loss: 1.894220 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 380 /1000;  Training Loss: 1.450410 ; Training Acc: 40.117\n",
      "Iteration: 380 /1000;  Testing Loss: 1.922074 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 381 /1000;  Training Loss: 1.430286 ; Training Acc: 41.096\n",
      "Iteration: 381 /1000;  Testing Loss: 1.895077 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 382 /1000;  Training Loss: 1.462086 ; Training Acc: 40.117\n",
      "Iteration: 382 /1000;  Testing Loss: 1.950649 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 383 /1000;  Training Loss: 1.492329 ; Training Acc: 38.160\n",
      "Iteration: 383 /1000;  Testing Loss: 1.959020 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 384 /1000;  Training Loss: 1.482156 ; Training Acc: 38.356\n",
      "Iteration: 384 /1000;  Testing Loss: 1.889760 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 385 /1000;  Training Loss: 1.418729 ; Training Acc: 42.857\n",
      "Iteration: 385 /1000;  Testing Loss: 1.910112 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 386 /1000;  Training Loss: 1.434732 ; Training Acc: 40.509\n",
      "Iteration: 386 /1000;  Testing Loss: 1.872263 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 387 /1000;  Training Loss: 1.439349 ; Training Acc: 41.683\n",
      "Iteration: 387 /1000;  Testing Loss: 1.876834 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 388 /1000;  Training Loss: 1.431298 ; Training Acc: 40.509\n",
      "Iteration: 388 /1000;  Testing Loss: 1.874634 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 389 /1000;  Training Loss: 1.416637 ; Training Acc: 43.249\n",
      "Iteration: 389 /1000;  Testing Loss: 1.906074 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 390 /1000;  Training Loss: 1.437994 ; Training Acc: 42.661\n",
      "Iteration: 390 /1000;  Testing Loss: 1.964678 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 391 /1000;  Training Loss: 1.424952 ; Training Acc: 41.292\n",
      "Iteration: 391 /1000;  Testing Loss: 1.878230 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 392 /1000;  Training Loss: 1.419377 ; Training Acc: 40.900\n",
      "Iteration: 392 /1000;  Testing Loss: 1.872493 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 393 /1000;  Training Loss: 1.427855 ; Training Acc: 41.879\n",
      "Iteration: 393 /1000;  Testing Loss: 1.882627 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 394 /1000;  Training Loss: 1.421367 ; Training Acc: 42.074\n",
      "Iteration: 394 /1000;  Testing Loss: 1.860879 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 395 /1000;  Training Loss: 1.433383 ; Training Acc: 39.530\n",
      "Iteration: 395 /1000;  Testing Loss: 1.920969 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 396 /1000;  Training Loss: 1.516896 ; Training Acc: 36.204\n",
      "Iteration: 396 /1000;  Testing Loss: 1.885456 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 397 /1000;  Training Loss: 1.483364 ; Training Acc: 37.965\n",
      "Iteration: 397 /1000;  Testing Loss: 1.887302 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 398 /1000;  Training Loss: 1.458921 ; Training Acc: 38.748\n",
      "Iteration: 398 /1000;  Testing Loss: 1.907204 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 399 /1000;  Training Loss: 1.424730 ; Training Acc: 41.879\n",
      "Iteration: 399 /1000;  Testing Loss: 1.871957 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 400 /1000;  Training Loss: 1.473319 ; Training Acc: 39.139\n",
      "Iteration: 400 /1000;  Testing Loss: 1.919860 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 401 /1000;  Training Loss: 1.423348 ; Training Acc: 41.683\n",
      "Iteration: 401 /1000;  Testing Loss: 1.967460 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 402 /1000;  Training Loss: 1.420099 ; Training Acc: 42.270\n",
      "Iteration: 402 /1000;  Testing Loss: 1.858719 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 403 /1000;  Training Loss: 1.517718 ; Training Acc: 33.659\n",
      "Iteration: 403 /1000;  Testing Loss: 1.879494 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 404 /1000;  Training Loss: 1.459019 ; Training Acc: 39.530\n",
      "Iteration: 404 /1000;  Testing Loss: 1.932138 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 405 /1000;  Training Loss: 1.418908 ; Training Acc: 41.096\n",
      "Iteration: 405 /1000;  Testing Loss: 1.857313 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 406 /1000;  Training Loss: 1.420808 ; Training Acc: 41.879\n",
      "Iteration: 406 /1000;  Testing Loss: 1.867287 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 407 /1000;  Training Loss: 1.405386 ; Training Acc: 43.249\n",
      "Iteration: 407 /1000;  Testing Loss: 1.920523 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 408 /1000;  Training Loss: 1.421873 ; Training Acc: 40.313\n",
      "Iteration: 408 /1000;  Testing Loss: 1.904469 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 409 /1000;  Training Loss: 1.421725 ; Training Acc: 40.509\n",
      "Iteration: 409 /1000;  Testing Loss: 1.859199 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 410 /1000;  Training Loss: 1.466640 ; Training Acc: 37.182\n",
      "Iteration: 410 /1000;  Testing Loss: 1.866256 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 411 /1000;  Training Loss: 1.426596 ; Training Acc: 41.683\n",
      "Iteration: 411 /1000;  Testing Loss: 1.908916 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 412 /1000;  Training Loss: 1.413919 ; Training Acc: 41.487\n",
      "Iteration: 412 /1000;  Testing Loss: 1.887041 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 413 /1000;  Training Loss: 1.425951 ; Training Acc: 43.053\n",
      "Iteration: 413 /1000;  Testing Loss: 1.902835 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 414 /1000;  Training Loss: 1.433214 ; Training Acc: 40.900\n",
      "Iteration: 414 /1000;  Testing Loss: 1.904578 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 415 /1000;  Training Loss: 1.420124 ; Training Acc: 40.705\n",
      "Iteration: 415 /1000;  Testing Loss: 1.861281 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 416 /1000;  Training Loss: 1.408857 ; Training Acc: 40.900\n",
      "Iteration: 416 /1000;  Testing Loss: 1.916132 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 417 /1000;  Training Loss: 1.411567 ; Training Acc: 41.487\n",
      "Iteration: 417 /1000;  Testing Loss: 1.855339 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 418 /1000;  Training Loss: 1.419123 ; Training Acc: 40.900\n",
      "Iteration: 418 /1000;  Testing Loss: 1.858054 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 419 /1000;  Training Loss: 1.404272 ; Training Acc: 43.836\n",
      "Iteration: 419 /1000;  Testing Loss: 1.921867 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 420 /1000;  Training Loss: 1.411921 ; Training Acc: 42.270\n",
      "Iteration: 420 /1000;  Testing Loss: 1.850663 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 421 /1000;  Training Loss: 1.404236 ; Training Acc: 43.444\n",
      "Iteration: 421 /1000;  Testing Loss: 1.848853 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 422 /1000;  Training Loss: 1.402715 ; Training Acc: 42.466\n",
      "Iteration: 422 /1000;  Testing Loss: 1.899287 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 423 /1000;  Training Loss: 1.408858 ; Training Acc: 40.509\n",
      "Iteration: 423 /1000;  Testing Loss: 1.902585 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 424 /1000;  Training Loss: 1.407706 ; Training Acc: 41.487\n",
      "Iteration: 424 /1000;  Testing Loss: 1.867186 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 425 /1000;  Training Loss: 1.389903 ; Training Acc: 44.227\n",
      "Iteration: 425 /1000;  Testing Loss: 1.871283 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 426 /1000;  Training Loss: 1.406127 ; Training Acc: 43.053\n",
      "Iteration: 426 /1000;  Testing Loss: 1.841892 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 427 /1000;  Training Loss: 1.421565 ; Training Acc: 43.444\n",
      "Iteration: 427 /1000;  Testing Loss: 1.924661 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 428 /1000;  Training Loss: 1.408172 ; Training Acc: 43.640\n",
      "Iteration: 428 /1000;  Testing Loss: 1.846928 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 429 /1000;  Training Loss: 1.410444 ; Training Acc: 41.683\n",
      "Iteration: 429 /1000;  Testing Loss: 1.876925 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 430 /1000;  Training Loss: 1.410884 ; Training Acc: 42.074\n",
      "Iteration: 430 /1000;  Testing Loss: 1.838958 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 431 /1000;  Training Loss: 1.455059 ; Training Acc: 38.943\n",
      "Iteration: 431 /1000;  Testing Loss: 1.905178 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 432 /1000;  Training Loss: 1.389387 ; Training Acc: 43.053\n",
      "Iteration: 432 /1000;  Testing Loss: 1.879214 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 433 /1000;  Training Loss: 1.391744 ; Training Acc: 41.879\n",
      "Iteration: 433 /1000;  Testing Loss: 1.861360 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 434 /1000;  Training Loss: 1.381804 ; Training Acc: 43.836\n",
      "Iteration: 434 /1000;  Testing Loss: 1.838880 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 435 /1000;  Training Loss: 1.402264 ; Training Acc: 42.270\n",
      "Iteration: 435 /1000;  Testing Loss: 1.930726 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 436 /1000;  Training Loss: 1.420280 ; Training Acc: 42.270\n",
      "Iteration: 436 /1000;  Testing Loss: 1.836365 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 437 /1000;  Training Loss: 1.398586 ; Training Acc: 42.074\n",
      "Iteration: 437 /1000;  Testing Loss: 1.860412 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 438 /1000;  Training Loss: 1.402067 ; Training Acc: 42.661\n",
      "Iteration: 438 /1000;  Testing Loss: 1.838223 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 439 /1000;  Training Loss: 1.468874 ; Training Acc: 37.769\n",
      "Iteration: 439 /1000;  Testing Loss: 2.081246 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 440 /1000;  Training Loss: 1.423116 ; Training Acc: 40.313\n",
      "Iteration: 440 /1000;  Testing Loss: 1.858351 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 441 /1000;  Training Loss: 1.390385 ; Training Acc: 42.857\n",
      "Iteration: 441 /1000;  Testing Loss: 1.854366 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 442 /1000;  Training Loss: 1.408404 ; Training Acc: 41.879\n",
      "Iteration: 442 /1000;  Testing Loss: 1.923820 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 443 /1000;  Training Loss: 1.455821 ; Training Acc: 38.552\n",
      "Iteration: 443 /1000;  Testing Loss: 1.835938 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 444 /1000;  Training Loss: 1.427168 ; Training Acc: 38.748\n",
      "Iteration: 444 /1000;  Testing Loss: 1.936565 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 445 /1000;  Training Loss: 1.412768 ; Training Acc: 42.074\n",
      "Iteration: 445 /1000;  Testing Loss: 1.852714 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 446 /1000;  Training Loss: 1.408974 ; Training Acc: 43.053\n",
      "Iteration: 446 /1000;  Testing Loss: 1.870705 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 447 /1000;  Training Loss: 1.435722 ; Training Acc: 39.726\n",
      "Iteration: 447 /1000;  Testing Loss: 1.838514 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 448 /1000;  Training Loss: 1.388216 ; Training Acc: 42.466\n",
      "Iteration: 448 /1000;  Testing Loss: 1.876500 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 449 /1000;  Training Loss: 1.381587 ; Training Acc: 43.836\n",
      "Iteration: 449 /1000;  Testing Loss: 1.848709 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 450 /1000;  Training Loss: 1.381983 ; Training Acc: 42.074\n",
      "Iteration: 450 /1000;  Testing Loss: 1.888514 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 451 /1000;  Training Loss: 1.388493 ; Training Acc: 42.661\n",
      "Iteration: 451 /1000;  Testing Loss: 1.861090 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 452 /1000;  Training Loss: 1.403621 ; Training Acc: 39.335\n",
      "Iteration: 452 /1000;  Testing Loss: 1.843970 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 453 /1000;  Training Loss: 1.396997 ; Training Acc: 42.074\n",
      "Iteration: 453 /1000;  Testing Loss: 1.857059 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 454 /1000;  Training Loss: 1.381262 ; Training Acc: 44.031\n",
      "Iteration: 454 /1000;  Testing Loss: 1.839086 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 455 /1000;  Training Loss: 1.386016 ; Training Acc: 43.053\n",
      "Iteration: 455 /1000;  Testing Loss: 1.861636 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 456 /1000;  Training Loss: 1.395875 ; Training Acc: 41.683\n",
      "Iteration: 456 /1000;  Testing Loss: 1.918230 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 457 /1000;  Training Loss: 1.377033 ; Training Acc: 43.249\n",
      "Iteration: 457 /1000;  Testing Loss: 1.852865 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 458 /1000;  Training Loss: 1.419607 ; Training Acc: 41.096\n",
      "Iteration: 458 /1000;  Testing Loss: 1.888598 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 459 /1000;  Training Loss: 1.385162 ; Training Acc: 43.249\n",
      "Iteration: 459 /1000;  Testing Loss: 1.838403 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 460 /1000;  Training Loss: 1.379957 ; Training Acc: 43.249\n",
      "Iteration: 460 /1000;  Testing Loss: 1.938827 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 461 /1000;  Training Loss: 1.438689 ; Training Acc: 40.117\n",
      "Iteration: 461 /1000;  Testing Loss: 1.833033 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 462 /1000;  Training Loss: 1.395033 ; Training Acc: 42.074\n",
      "Iteration: 462 /1000;  Testing Loss: 1.863586 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 463 /1000;  Training Loss: 1.373892 ; Training Acc: 43.053\n",
      "Iteration: 463 /1000;  Testing Loss: 1.905753 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 464 /1000;  Training Loss: 1.406258 ; Training Acc: 40.117\n",
      "Iteration: 464 /1000;  Testing Loss: 1.826753 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 465 /1000;  Training Loss: 1.453067 ; Training Acc: 41.292\n",
      "Iteration: 465 /1000;  Testing Loss: 1.918689 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 466 /1000;  Training Loss: 1.389816 ; Training Acc: 41.487\n",
      "Iteration: 466 /1000;  Testing Loss: 1.822844 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 467 /1000;  Training Loss: 1.392178 ; Training Acc: 41.487\n",
      "Iteration: 467 /1000;  Testing Loss: 1.879736 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 468 /1000;  Training Loss: 1.366317 ; Training Acc: 43.444\n",
      "Iteration: 468 /1000;  Testing Loss: 1.825343 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 469 /1000;  Training Loss: 1.362244 ; Training Acc: 43.053\n",
      "Iteration: 469 /1000;  Testing Loss: 1.834745 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 470 /1000;  Training Loss: 1.373965 ; Training Acc: 43.249\n",
      "Iteration: 470 /1000;  Testing Loss: 1.826022 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 471 /1000;  Training Loss: 1.383790 ; Training Acc: 41.487\n",
      "Iteration: 471 /1000;  Testing Loss: 1.899914 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 472 /1000;  Training Loss: 1.372042 ; Training Acc: 43.836\n",
      "Iteration: 472 /1000;  Testing Loss: 1.863043 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 473 /1000;  Training Loss: 1.389994 ; Training Acc: 41.487\n",
      "Iteration: 473 /1000;  Testing Loss: 1.830549 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 474 /1000;  Training Loss: 1.369462 ; Training Acc: 41.879\n",
      "Iteration: 474 /1000;  Testing Loss: 1.827909 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 475 /1000;  Training Loss: 1.359096 ; Training Acc: 43.640\n",
      "Iteration: 475 /1000;  Testing Loss: 1.863705 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 476 /1000;  Training Loss: 1.361270 ; Training Acc: 43.249\n",
      "Iteration: 476 /1000;  Testing Loss: 1.829519 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 477 /1000;  Training Loss: 1.365680 ; Training Acc: 44.227\n",
      "Iteration: 477 /1000;  Testing Loss: 1.827706 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 478 /1000;  Training Loss: 1.426894 ; Training Acc: 39.139\n",
      "Iteration: 478 /1000;  Testing Loss: 1.928724 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 479 /1000;  Training Loss: 1.459187 ; Training Acc: 39.335\n",
      "Iteration: 479 /1000;  Testing Loss: 1.848741 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 480 /1000;  Training Loss: 1.413353 ; Training Acc: 40.313\n",
      "Iteration: 480 /1000;  Testing Loss: 1.822520 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 481 /1000;  Training Loss: 1.426632 ; Training Acc: 38.552\n",
      "Iteration: 481 /1000;  Testing Loss: 1.865543 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 482 /1000;  Training Loss: 1.422319 ; Training Acc: 37.573\n",
      "Iteration: 482 /1000;  Testing Loss: 1.836608 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 483 /1000;  Training Loss: 1.391842 ; Training Acc: 39.922\n",
      "Iteration: 483 /1000;  Testing Loss: 1.953870 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 484 /1000;  Training Loss: 1.377522 ; Training Acc: 41.683\n",
      "Iteration: 484 /1000;  Testing Loss: 1.823375 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 485 /1000;  Training Loss: 1.361685 ; Training Acc: 42.857\n",
      "Iteration: 485 /1000;  Testing Loss: 1.957188 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 486 /1000;  Training Loss: 1.409909 ; Training Acc: 38.160\n",
      "Iteration: 486 /1000;  Testing Loss: 1.853322 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 487 /1000;  Training Loss: 1.380640 ; Training Acc: 43.249\n",
      "Iteration: 487 /1000;  Testing Loss: 1.843664 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 488 /1000;  Training Loss: 1.377130 ; Training Acc: 40.117\n",
      "Iteration: 488 /1000;  Testing Loss: 1.849849 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 489 /1000;  Training Loss: 1.379754 ; Training Acc: 41.683\n",
      "Iteration: 489 /1000;  Testing Loss: 1.976684 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 490 /1000;  Training Loss: 1.392612 ; Training Acc: 40.117\n",
      "Iteration: 490 /1000;  Testing Loss: 1.817343 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 491 /1000;  Training Loss: 1.377416 ; Training Acc: 40.509\n",
      "Iteration: 491 /1000;  Testing Loss: 1.909720 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 492 /1000;  Training Loss: 1.371345 ; Training Acc: 39.726\n",
      "Iteration: 492 /1000;  Testing Loss: 1.814037 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 493 /1000;  Training Loss: 1.359751 ; Training Acc: 42.270\n",
      "Iteration: 493 /1000;  Testing Loss: 1.863594 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 494 /1000;  Training Loss: 1.369594 ; Training Acc: 41.487\n",
      "Iteration: 494 /1000;  Testing Loss: 1.814145 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 495 /1000;  Training Loss: 1.373969 ; Training Acc: 41.683\n",
      "Iteration: 495 /1000;  Testing Loss: 1.926244 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 496 /1000;  Training Loss: 1.378205 ; Training Acc: 42.270\n",
      "Iteration: 496 /1000;  Testing Loss: 1.855276 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 497 /1000;  Training Loss: 1.433651 ; Training Acc: 42.857\n",
      "Iteration: 497 /1000;  Testing Loss: 1.984199 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 498 /1000;  Training Loss: 1.404330 ; Training Acc: 40.117\n",
      "Iteration: 498 /1000;  Testing Loss: 1.811801 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 499 /1000;  Training Loss: 1.382382 ; Training Acc: 40.509\n",
      "Iteration: 499 /1000;  Testing Loss: 2.154332 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 500 /1000;  Training Loss: 1.408077 ; Training Acc: 38.943\n",
      "Iteration: 500 /1000;  Testing Loss: 1.807509 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 501 /1000;  Training Loss: 1.357784 ; Training Acc: 42.270\n",
      "Iteration: 501 /1000;  Testing Loss: 1.812290 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 502 /1000;  Training Loss: 1.349134 ; Training Acc: 41.879\n",
      "Iteration: 502 /1000;  Testing Loss: 1.895569 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 503 /1000;  Training Loss: 1.360948 ; Training Acc: 41.096\n",
      "Iteration: 503 /1000;  Testing Loss: 1.864367 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 504 /1000;  Training Loss: 1.367021 ; Training Acc: 42.270\n",
      "Iteration: 504 /1000;  Testing Loss: 1.882953 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 505 /1000;  Training Loss: 1.352432 ; Training Acc: 41.879\n",
      "Iteration: 505 /1000;  Testing Loss: 1.865375 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 506 /1000;  Training Loss: 1.348607 ; Training Acc: 42.074\n",
      "Iteration: 506 /1000;  Testing Loss: 1.819479 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 507 /1000;  Training Loss: 1.376653 ; Training Acc: 39.530\n",
      "Iteration: 507 /1000;  Testing Loss: 1.810592 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 508 /1000;  Training Loss: 1.372301 ; Training Acc: 40.509\n",
      "Iteration: 508 /1000;  Testing Loss: 1.828486 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 509 /1000;  Training Loss: 1.356868 ; Training Acc: 41.487\n",
      "Iteration: 509 /1000;  Testing Loss: 1.918729 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 510 /1000;  Training Loss: 1.409365 ; Training Acc: 38.160\n",
      "Iteration: 510 /1000;  Testing Loss: 1.807295 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 511 /1000;  Training Loss: 1.350174 ; Training Acc: 41.096\n",
      "Iteration: 511 /1000;  Testing Loss: 1.866429 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 512 /1000;  Training Loss: 1.345405 ; Training Acc: 41.879\n",
      "Iteration: 512 /1000;  Testing Loss: 1.808667 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 513 /1000;  Training Loss: 1.344263 ; Training Acc: 41.683\n",
      "Iteration: 513 /1000;  Testing Loss: 1.871815 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 514 /1000;  Training Loss: 1.337481 ; Training Acc: 42.857\n",
      "Iteration: 514 /1000;  Testing Loss: 1.805950 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 515 /1000;  Training Loss: 1.355036 ; Training Acc: 42.661\n",
      "Iteration: 515 /1000;  Testing Loss: 1.827461 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 516 /1000;  Training Loss: 1.360524 ; Training Acc: 41.487\n",
      "Iteration: 516 /1000;  Testing Loss: 1.843087 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 517 /1000;  Training Loss: 1.356035 ; Training Acc: 42.074\n",
      "Iteration: 517 /1000;  Testing Loss: 1.804977 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 518 /1000;  Training Loss: 1.349477 ; Training Acc: 42.466\n",
      "Iteration: 518 /1000;  Testing Loss: 1.959395 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 519 /1000;  Training Loss: 1.398823 ; Training Acc: 40.313\n",
      "Iteration: 519 /1000;  Testing Loss: 1.807450 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 520 /1000;  Training Loss: 1.389742 ; Training Acc: 37.378\n",
      "Iteration: 520 /1000;  Testing Loss: 1.966363 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 521 /1000;  Training Loss: 1.382182 ; Training Acc: 39.922\n",
      "Iteration: 521 /1000;  Testing Loss: 1.800755 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 522 /1000;  Training Loss: 1.338561 ; Training Acc: 43.249\n",
      "Iteration: 522 /1000;  Testing Loss: 1.899578 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 523 /1000;  Training Loss: 1.358259 ; Training Acc: 40.900\n",
      "Iteration: 523 /1000;  Testing Loss: 1.872706 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 524 /1000;  Training Loss: 1.374243 ; Training Acc: 41.096\n",
      "Iteration: 524 /1000;  Testing Loss: 1.798679 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 525 /1000;  Training Loss: 1.342113 ; Training Acc: 41.879\n",
      "Iteration: 525 /1000;  Testing Loss: 1.799150 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 526 /1000;  Training Loss: 1.369799 ; Training Acc: 40.705\n",
      "Iteration: 526 /1000;  Testing Loss: 1.919960 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 527 /1000;  Training Loss: 1.357423 ; Training Acc: 42.466\n",
      "Iteration: 527 /1000;  Testing Loss: 1.819377 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 528 /1000;  Training Loss: 1.335403 ; Training Acc: 39.530\n",
      "Iteration: 528 /1000;  Testing Loss: 1.852255 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 529 /1000;  Training Loss: 1.406748 ; Training Acc: 39.922\n",
      "Iteration: 529 /1000;  Testing Loss: 1.819715 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 530 /1000;  Training Loss: 1.368632 ; Training Acc: 41.292\n",
      "Iteration: 530 /1000;  Testing Loss: 1.982694 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 531 /1000;  Training Loss: 1.345361 ; Training Acc: 40.117\n",
      "Iteration: 531 /1000;  Testing Loss: 1.815196 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 532 /1000;  Training Loss: 1.348097 ; Training Acc: 41.292\n",
      "Iteration: 532 /1000;  Testing Loss: 1.877272 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 533 /1000;  Training Loss: 1.343776 ; Training Acc: 39.530\n",
      "Iteration: 533 /1000;  Testing Loss: 1.828201 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 534 /1000;  Training Loss: 1.349525 ; Training Acc: 39.530\n",
      "Iteration: 534 /1000;  Testing Loss: 1.797775 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 535 /1000;  Training Loss: 1.347171 ; Training Acc: 40.900\n",
      "Iteration: 535 /1000;  Testing Loss: 1.798197 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 536 /1000;  Training Loss: 1.387043 ; Training Acc: 37.378\n",
      "Iteration: 536 /1000;  Testing Loss: 1.908425 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 537 /1000;  Training Loss: 1.344182 ; Training Acc: 41.683\n",
      "Iteration: 537 /1000;  Testing Loss: 1.809763 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 538 /1000;  Training Loss: 1.319676 ; Training Acc: 41.879\n",
      "Iteration: 538 /1000;  Testing Loss: 1.792642 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 539 /1000;  Training Loss: 1.334298 ; Training Acc: 40.509\n",
      "Iteration: 539 /1000;  Testing Loss: 1.878401 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 540 /1000;  Training Loss: 1.342897 ; Training Acc: 39.139\n",
      "Iteration: 540 /1000;  Testing Loss: 1.792511 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 541 /1000;  Training Loss: 1.341974 ; Training Acc: 40.117\n",
      "Iteration: 541 /1000;  Testing Loss: 1.798832 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 542 /1000;  Training Loss: 1.333549 ; Training Acc: 40.705\n",
      "Iteration: 542 /1000;  Testing Loss: 1.860702 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 543 /1000;  Training Loss: 1.332366 ; Training Acc: 40.117\n",
      "Iteration: 543 /1000;  Testing Loss: 1.860154 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 544 /1000;  Training Loss: 1.328033 ; Training Acc: 40.705\n",
      "Iteration: 544 /1000;  Testing Loss: 1.790768 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 545 /1000;  Training Loss: 1.332736 ; Training Acc: 40.117\n",
      "Iteration: 545 /1000;  Testing Loss: 1.893416 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 546 /1000;  Training Loss: 1.321929 ; Training Acc: 40.313\n",
      "Iteration: 546 /1000;  Testing Loss: 1.799085 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 547 /1000;  Training Loss: 1.325791 ; Training Acc: 39.922\n",
      "Iteration: 547 /1000;  Testing Loss: 1.793851 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 548 /1000;  Training Loss: 1.341013 ; Training Acc: 39.922\n",
      "Iteration: 548 /1000;  Testing Loss: 1.790439 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 549 /1000;  Training Loss: 1.328132 ; Training Acc: 40.705\n",
      "Iteration: 549 /1000;  Testing Loss: 1.798727 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 550 /1000;  Training Loss: 1.324999 ; Training Acc: 40.313\n",
      "Iteration: 550 /1000;  Testing Loss: 1.788915 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 551 /1000;  Training Loss: 1.313841 ; Training Acc: 41.487\n",
      "Iteration: 551 /1000;  Testing Loss: 1.798253 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 552 /1000;  Training Loss: 1.315381 ; Training Acc: 41.879\n",
      "Iteration: 552 /1000;  Testing Loss: 1.833872 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 553 /1000;  Training Loss: 1.313874 ; Training Acc: 40.313\n",
      "Iteration: 553 /1000;  Testing Loss: 1.790658 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 554 /1000;  Training Loss: 1.318978 ; Training Acc: 40.117\n",
      "Iteration: 554 /1000;  Testing Loss: 1.822975 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 555 /1000;  Training Loss: 1.358571 ; Training Acc: 38.160\n",
      "Iteration: 555 /1000;  Testing Loss: 1.842186 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 556 /1000;  Training Loss: 1.377077 ; Training Acc: 38.356\n",
      "Iteration: 556 /1000;  Testing Loss: 1.813635 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 557 /1000;  Training Loss: 1.314346 ; Training Acc: 40.313\n",
      "Iteration: 557 /1000;  Testing Loss: 1.827659 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 558 /1000;  Training Loss: 1.345918 ; Training Acc: 39.335\n",
      "Iteration: 558 /1000;  Testing Loss: 1.881997 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 559 /1000;  Training Loss: 1.311533 ; Training Acc: 40.509\n",
      "Iteration: 559 /1000;  Testing Loss: 1.810388 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 560 /1000;  Training Loss: 1.332605 ; Training Acc: 38.748\n",
      "Iteration: 560 /1000;  Testing Loss: 1.817298 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 561 /1000;  Training Loss: 1.328281 ; Training Acc: 40.900\n",
      "Iteration: 561 /1000;  Testing Loss: 2.013665 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 562 /1000;  Training Loss: 1.340316 ; Training Acc: 39.335\n",
      "Iteration: 562 /1000;  Testing Loss: 1.808998 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 563 /1000;  Training Loss: 1.314102 ; Training Acc: 41.292\n",
      "Iteration: 563 /1000;  Testing Loss: 1.786006 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 564 /1000;  Training Loss: 1.318819 ; Training Acc: 40.117\n",
      "Iteration: 564 /1000;  Testing Loss: 1.823839 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 565 /1000;  Training Loss: 1.307158 ; Training Acc: 41.292\n",
      "Iteration: 565 /1000;  Testing Loss: 1.790785 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 566 /1000;  Training Loss: 1.327826 ; Training Acc: 40.705\n",
      "Iteration: 566 /1000;  Testing Loss: 1.992721 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 567 /1000;  Training Loss: 1.337154 ; Training Acc: 41.096\n",
      "Iteration: 567 /1000;  Testing Loss: 1.798263 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 568 /1000;  Training Loss: 1.315690 ; Training Acc: 41.487\n",
      "Iteration: 568 /1000;  Testing Loss: 1.858461 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 569 /1000;  Training Loss: 1.315193 ; Training Acc: 41.292\n",
      "Iteration: 569 /1000;  Testing Loss: 1.793950 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 570 /1000;  Training Loss: 1.334462 ; Training Acc: 39.530\n",
      "Iteration: 570 /1000;  Testing Loss: 1.892001 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 571 /1000;  Training Loss: 1.333402 ; Training Acc: 40.313\n",
      "Iteration: 571 /1000;  Testing Loss: 1.797759 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 572 /1000;  Training Loss: 1.299836 ; Training Acc: 40.705\n",
      "Iteration: 572 /1000;  Testing Loss: 1.780728 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 573 /1000;  Training Loss: 1.300470 ; Training Acc: 41.487\n",
      "Iteration: 573 /1000;  Testing Loss: 1.828733 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 574 /1000;  Training Loss: 1.305166 ; Training Acc: 41.292\n",
      "Iteration: 574 /1000;  Testing Loss: 1.819665 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 575 /1000;  Training Loss: 1.356238 ; Training Acc: 38.748\n",
      "Iteration: 575 /1000;  Testing Loss: 1.848827 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 576 /1000;  Training Loss: 1.379994 ; Training Acc: 37.769\n",
      "Iteration: 576 /1000;  Testing Loss: 2.113903 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 577 /1000;  Training Loss: 1.366468 ; Training Acc: 38.943\n",
      "Iteration: 577 /1000;  Testing Loss: 1.803316 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 578 /1000;  Training Loss: 1.302035 ; Training Acc: 41.292\n",
      "Iteration: 578 /1000;  Testing Loss: 1.777207 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 579 /1000;  Training Loss: 1.300217 ; Training Acc: 40.900\n",
      "Iteration: 579 /1000;  Testing Loss: 1.778436 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 580 /1000;  Training Loss: 1.332402 ; Training Acc: 39.530\n",
      "Iteration: 580 /1000;  Testing Loss: 2.084318 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 581 /1000;  Training Loss: 1.427860 ; Training Acc: 36.791\n",
      "Iteration: 581 /1000;  Testing Loss: 1.783000 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 582 /1000;  Training Loss: 1.332563 ; Training Acc: 40.117\n",
      "Iteration: 582 /1000;  Testing Loss: 1.778757 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 583 /1000;  Training Loss: 1.309115 ; Training Acc: 41.683\n",
      "Iteration: 583 /1000;  Testing Loss: 1.771121 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 584 /1000;  Training Loss: 1.339353 ; Training Acc: 39.726\n",
      "Iteration: 584 /1000;  Testing Loss: 1.772262 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 585 /1000;  Training Loss: 1.342662 ; Training Acc: 39.335\n",
      "Iteration: 585 /1000;  Testing Loss: 1.917766 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 586 /1000;  Training Loss: 1.336093 ; Training Acc: 39.335\n",
      "Iteration: 586 /1000;  Testing Loss: 1.815076 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 587 /1000;  Training Loss: 1.329005 ; Training Acc: 39.726\n",
      "Iteration: 587 /1000;  Testing Loss: 1.889534 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 588 /1000;  Training Loss: 1.329828 ; Training Acc: 39.335\n",
      "Iteration: 588 /1000;  Testing Loss: 1.841090 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 589 /1000;  Training Loss: 1.317018 ; Training Acc: 40.509\n",
      "Iteration: 589 /1000;  Testing Loss: 1.770102 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 590 /1000;  Training Loss: 1.297612 ; Training Acc: 41.292\n",
      "Iteration: 590 /1000;  Testing Loss: 1.886602 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 591 /1000;  Training Loss: 1.305205 ; Training Acc: 41.292\n",
      "Iteration: 591 /1000;  Testing Loss: 1.791367 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 592 /1000;  Training Loss: 1.301406 ; Training Acc: 40.313\n",
      "Iteration: 592 /1000;  Testing Loss: 1.769943 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 593 /1000;  Training Loss: 1.294025 ; Training Acc: 41.683\n",
      "Iteration: 593 /1000;  Testing Loss: 1.794996 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 594 /1000;  Training Loss: 1.303392 ; Training Acc: 40.509\n",
      "Iteration: 594 /1000;  Testing Loss: 1.771885 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 595 /1000;  Training Loss: 1.289568 ; Training Acc: 41.683\n",
      "Iteration: 595 /1000;  Testing Loss: 1.774587 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 596 /1000;  Training Loss: 1.296754 ; Training Acc: 42.074\n",
      "Iteration: 596 /1000;  Testing Loss: 1.816649 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 597 /1000;  Training Loss: 1.306324 ; Training Acc: 39.530\n",
      "Iteration: 597 /1000;  Testing Loss: 1.889207 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 598 /1000;  Training Loss: 1.307136 ; Training Acc: 40.509\n",
      "Iteration: 598 /1000;  Testing Loss: 1.775323 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 599 /1000;  Training Loss: 1.300364 ; Training Acc: 40.509\n",
      "Iteration: 599 /1000;  Testing Loss: 1.795451 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 600 /1000;  Training Loss: 1.299476 ; Training Acc: 40.900\n",
      "Iteration: 600 /1000;  Testing Loss: 1.773367 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 601 /1000;  Training Loss: 1.306675 ; Training Acc: 40.705\n",
      "Iteration: 601 /1000;  Testing Loss: 1.788178 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 602 /1000;  Training Loss: 1.286467 ; Training Acc: 42.074\n",
      "Iteration: 602 /1000;  Testing Loss: 1.770234 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 603 /1000;  Training Loss: 1.340698 ; Training Acc: 38.160\n",
      "Iteration: 603 /1000;  Testing Loss: 1.981576 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 604 /1000;  Training Loss: 1.358929 ; Training Acc: 38.552\n",
      "Iteration: 604 /1000;  Testing Loss: 1.796532 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 605 /1000;  Training Loss: 1.364035 ; Training Acc: 38.943\n",
      "Iteration: 605 /1000;  Testing Loss: 1.769992 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 606 /1000;  Training Loss: 1.332471 ; Training Acc: 37.965\n",
      "Iteration: 606 /1000;  Testing Loss: 1.835634 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 607 /1000;  Training Loss: 1.298990 ; Training Acc: 41.096\n",
      "Iteration: 607 /1000;  Testing Loss: 1.769221 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 608 /1000;  Training Loss: 1.302274 ; Training Acc: 40.705\n",
      "Iteration: 608 /1000;  Testing Loss: 1.804769 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 609 /1000;  Training Loss: 1.317847 ; Training Acc: 40.705\n",
      "Iteration: 609 /1000;  Testing Loss: 1.770368 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 610 /1000;  Training Loss: 1.285456 ; Training Acc: 41.683\n",
      "Iteration: 610 /1000;  Testing Loss: 1.770786 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 611 /1000;  Training Loss: 1.284951 ; Training Acc: 42.074\n",
      "Iteration: 611 /1000;  Testing Loss: 1.814574 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 612 /1000;  Training Loss: 1.316805 ; Training Acc: 40.509\n",
      "Iteration: 612 /1000;  Testing Loss: 1.775578 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 613 /1000;  Training Loss: 1.294559 ; Training Acc: 41.292\n",
      "Iteration: 613 /1000;  Testing Loss: 1.769766 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 614 /1000;  Training Loss: 1.282881 ; Training Acc: 41.879\n",
      "Iteration: 614 /1000;  Testing Loss: 1.786655 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 615 /1000;  Training Loss: 1.291720 ; Training Acc: 41.292\n",
      "Iteration: 615 /1000;  Testing Loss: 1.834147 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 616 /1000;  Training Loss: 1.300805 ; Training Acc: 41.292\n",
      "Iteration: 616 /1000;  Testing Loss: 1.799938 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 617 /1000;  Training Loss: 1.284819 ; Training Acc: 41.487\n",
      "Iteration: 617 /1000;  Testing Loss: 1.768787 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 618 /1000;  Training Loss: 1.299283 ; Training Acc: 40.900\n",
      "Iteration: 618 /1000;  Testing Loss: 1.916938 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 619 /1000;  Training Loss: 1.337766 ; Training Acc: 38.748\n",
      "Iteration: 619 /1000;  Testing Loss: 1.920467 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 620 /1000;  Training Loss: 1.286494 ; Training Acc: 41.879\n",
      "Iteration: 620 /1000;  Testing Loss: 1.815659 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 621 /1000;  Training Loss: 1.286721 ; Training Acc: 41.879\n",
      "Iteration: 621 /1000;  Testing Loss: 1.834107 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 622 /1000;  Training Loss: 1.286755 ; Training Acc: 41.683\n",
      "Iteration: 622 /1000;  Testing Loss: 1.866856 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 623 /1000;  Training Loss: 1.278387 ; Training Acc: 43.053\n",
      "Iteration: 623 /1000;  Testing Loss: 1.770134 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 624 /1000;  Training Loss: 1.278236 ; Training Acc: 42.661\n",
      "Iteration: 624 /1000;  Testing Loss: 1.774208 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 625 /1000;  Training Loss: 1.287558 ; Training Acc: 41.879\n",
      "Iteration: 625 /1000;  Testing Loss: 1.823668 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 626 /1000;  Training Loss: 1.314996 ; Training Acc: 40.509\n",
      "Iteration: 626 /1000;  Testing Loss: 1.774356 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 627 /1000;  Training Loss: 1.283950 ; Training Acc: 41.683\n",
      "Iteration: 627 /1000;  Testing Loss: 1.803880 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 628 /1000;  Training Loss: 1.283649 ; Training Acc: 41.879\n",
      "Iteration: 628 /1000;  Testing Loss: 1.766632 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 629 /1000;  Training Loss: 1.286720 ; Training Acc: 41.096\n",
      "Iteration: 629 /1000;  Testing Loss: 1.825917 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 630 /1000;  Training Loss: 1.290878 ; Training Acc: 42.857\n",
      "Iteration: 630 /1000;  Testing Loss: 1.809800 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 631 /1000;  Training Loss: 1.303405 ; Training Acc: 41.292\n",
      "Iteration: 631 /1000;  Testing Loss: 1.843488 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 632 /1000;  Training Loss: 1.310407 ; Training Acc: 40.509\n",
      "Iteration: 632 /1000;  Testing Loss: 1.768727 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 633 /1000;  Training Loss: 1.278859 ; Training Acc: 42.661\n",
      "Iteration: 633 /1000;  Testing Loss: 1.776621 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 634 /1000;  Training Loss: 1.277865 ; Training Acc: 42.661\n",
      "Iteration: 634 /1000;  Testing Loss: 1.775214 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 635 /1000;  Training Loss: 1.286643 ; Training Acc: 41.683\n",
      "Iteration: 635 /1000;  Testing Loss: 1.796784 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 636 /1000;  Training Loss: 1.338533 ; Training Acc: 38.943\n",
      "Iteration: 636 /1000;  Testing Loss: 1.792538 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 637 /1000;  Training Loss: 1.316817 ; Training Acc: 39.335\n",
      "Iteration: 637 /1000;  Testing Loss: 1.809320 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 638 /1000;  Training Loss: 1.300371 ; Training Acc: 40.313\n",
      "Iteration: 638 /1000;  Testing Loss: 1.798541 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 639 /1000;  Training Loss: 1.300982 ; Training Acc: 40.705\n",
      "Iteration: 639 /1000;  Testing Loss: 1.767201 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 640 /1000;  Training Loss: 1.333522 ; Training Acc: 39.726\n",
      "Iteration: 640 /1000;  Testing Loss: 1.966171 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 641 /1000;  Training Loss: 1.338057 ; Training Acc: 40.117\n",
      "Iteration: 641 /1000;  Testing Loss: 1.760063 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 642 /1000;  Training Loss: 1.322549 ; Training Acc: 40.509\n",
      "Iteration: 642 /1000;  Testing Loss: 1.934979 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 643 /1000;  Training Loss: 1.314511 ; Training Acc: 39.922\n",
      "Iteration: 643 /1000;  Testing Loss: 1.893171 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 644 /1000;  Training Loss: 1.309726 ; Training Acc: 39.922\n",
      "Iteration: 644 /1000;  Testing Loss: 1.758039 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 645 /1000;  Training Loss: 1.278268 ; Training Acc: 42.466\n",
      "Iteration: 645 /1000;  Testing Loss: 1.757651 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 646 /1000;  Training Loss: 1.275772 ; Training Acc: 41.683\n",
      "Iteration: 646 /1000;  Testing Loss: 1.837567 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 647 /1000;  Training Loss: 1.303416 ; Training Acc: 40.313\n",
      "Iteration: 647 /1000;  Testing Loss: 1.757241 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 648 /1000;  Training Loss: 1.270103 ; Training Acc: 43.053\n",
      "Iteration: 648 /1000;  Testing Loss: 1.787989 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 649 /1000;  Training Loss: 1.271671 ; Training Acc: 42.857\n",
      "Iteration: 649 /1000;  Testing Loss: 1.759731 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 650 /1000;  Training Loss: 1.264638 ; Training Acc: 42.074\n",
      "Iteration: 650 /1000;  Testing Loss: 1.807542 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 651 /1000;  Training Loss: 1.300047 ; Training Acc: 41.292\n",
      "Iteration: 651 /1000;  Testing Loss: 1.819822 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 652 /1000;  Training Loss: 1.284704 ; Training Acc: 41.879\n",
      "Iteration: 652 /1000;  Testing Loss: 1.786812 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 653 /1000;  Training Loss: 1.291427 ; Training Acc: 41.683\n",
      "Iteration: 653 /1000;  Testing Loss: 1.967029 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 654 /1000;  Training Loss: 1.414794 ; Training Acc: 38.356\n",
      "Iteration: 654 /1000;  Testing Loss: 1.864269 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 655 /1000;  Training Loss: 1.447714 ; Training Acc: 35.616\n",
      "Iteration: 655 /1000;  Testing Loss: 1.931128 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 656 /1000;  Training Loss: 1.311640 ; Training Acc: 41.096\n",
      "Iteration: 656 /1000;  Testing Loss: 1.834867 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 657 /1000;  Training Loss: 1.298298 ; Training Acc: 41.292\n",
      "Iteration: 657 /1000;  Testing Loss: 1.753228 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 658 /1000;  Training Loss: 1.315056 ; Training Acc: 39.922\n",
      "Iteration: 658 /1000;  Testing Loss: 1.781514 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 659 /1000;  Training Loss: 1.275056 ; Training Acc: 42.270\n",
      "Iteration: 659 /1000;  Testing Loss: 1.835967 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 660 /1000;  Training Loss: 1.299274 ; Training Acc: 40.705\n",
      "Iteration: 660 /1000;  Testing Loss: 1.756934 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 661 /1000;  Training Loss: 1.264052 ; Training Acc: 41.292\n",
      "Iteration: 661 /1000;  Testing Loss: 1.755465 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 662 /1000;  Training Loss: 1.271872 ; Training Acc: 43.249\n",
      "Iteration: 662 /1000;  Testing Loss: 1.788149 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 663 /1000;  Training Loss: 1.290362 ; Training Acc: 40.705\n",
      "Iteration: 663 /1000;  Testing Loss: 1.765979 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 664 /1000;  Training Loss: 1.312778 ; Training Acc: 40.313\n",
      "Iteration: 664 /1000;  Testing Loss: 1.774792 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 665 /1000;  Training Loss: 1.307746 ; Training Acc: 39.726\n",
      "Iteration: 665 /1000;  Testing Loss: 1.757912 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 666 /1000;  Training Loss: 1.281636 ; Training Acc: 42.270\n",
      "Iteration: 666 /1000;  Testing Loss: 1.878294 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 667 /1000;  Training Loss: 1.275783 ; Training Acc: 40.313\n",
      "Iteration: 667 /1000;  Testing Loss: 1.752264 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 668 /1000;  Training Loss: 1.269123 ; Training Acc: 41.096\n",
      "Iteration: 668 /1000;  Testing Loss: 1.798586 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 669 /1000;  Training Loss: 1.328275 ; Training Acc: 40.117\n",
      "Iteration: 669 /1000;  Testing Loss: 1.751143 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 670 /1000;  Training Loss: 1.273455 ; Training Acc: 40.900\n",
      "Iteration: 670 /1000;  Testing Loss: 1.751961 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 671 /1000;  Training Loss: 1.289501 ; Training Acc: 41.292\n",
      "Iteration: 671 /1000;  Testing Loss: 1.938640 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 672 /1000;  Training Loss: 1.286261 ; Training Acc: 40.900\n",
      "Iteration: 672 /1000;  Testing Loss: 1.877607 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 673 /1000;  Training Loss: 1.286470 ; Training Acc: 41.096\n",
      "Iteration: 673 /1000;  Testing Loss: 1.754603 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 674 /1000;  Training Loss: 1.269720 ; Training Acc: 41.879\n",
      "Iteration: 674 /1000;  Testing Loss: 1.812882 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 675 /1000;  Training Loss: 1.296506 ; Training Acc: 41.487\n",
      "Iteration: 675 /1000;  Testing Loss: 1.809164 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 676 /1000;  Training Loss: 1.290775 ; Training Acc: 41.096\n",
      "Iteration: 676 /1000;  Testing Loss: 1.831118 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 677 /1000;  Training Loss: 1.271981 ; Training Acc: 40.117\n",
      "Iteration: 677 /1000;  Testing Loss: 1.750828 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 678 /1000;  Training Loss: 1.290786 ; Training Acc: 39.922\n",
      "Iteration: 678 /1000;  Testing Loss: 1.758608 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 679 /1000;  Training Loss: 1.292416 ; Training Acc: 41.096\n",
      "Iteration: 679 /1000;  Testing Loss: 1.755403 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 680 /1000;  Training Loss: 1.402985 ; Training Acc: 36.595\n",
      "Iteration: 680 /1000;  Testing Loss: 1.927520 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 681 /1000;  Training Loss: 1.443621 ; Training Acc: 35.225\n",
      "Iteration: 681 /1000;  Testing Loss: 1.747486 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 682 /1000;  Training Loss: 1.336813 ; Training Acc: 39.139\n",
      "Iteration: 682 /1000;  Testing Loss: 1.895253 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 683 /1000;  Training Loss: 1.285258 ; Training Acc: 40.900\n",
      "Iteration: 683 /1000;  Testing Loss: 1.746278 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 684 /1000;  Training Loss: 1.259337 ; Training Acc: 42.661\n",
      "Iteration: 684 /1000;  Testing Loss: 1.753209 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 685 /1000;  Training Loss: 1.263125 ; Training Acc: 44.227\n",
      "Iteration: 685 /1000;  Testing Loss: 1.822993 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 686 /1000;  Training Loss: 1.263865 ; Training Acc: 42.857\n",
      "Iteration: 686 /1000;  Testing Loss: 1.757814 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 687 /1000;  Training Loss: 1.270684 ; Training Acc: 40.900\n",
      "Iteration: 687 /1000;  Testing Loss: 1.754236 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 688 /1000;  Training Loss: 1.260603 ; Training Acc: 42.270\n",
      "Iteration: 688 /1000;  Testing Loss: 1.768211 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 689 /1000;  Training Loss: 1.263151 ; Training Acc: 43.249\n",
      "Iteration: 689 /1000;  Testing Loss: 1.765390 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 690 /1000;  Training Loss: 1.261956 ; Training Acc: 43.053\n",
      "Iteration: 690 /1000;  Testing Loss: 1.746409 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 691 /1000;  Training Loss: 1.275833 ; Training Acc: 40.900\n",
      "Iteration: 691 /1000;  Testing Loss: 1.925012 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 692 /1000;  Training Loss: 1.321134 ; Training Acc: 40.313\n",
      "Iteration: 692 /1000;  Testing Loss: 1.745355 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 693 /1000;  Training Loss: 1.283665 ; Training Acc: 41.879\n",
      "Iteration: 693 /1000;  Testing Loss: 1.745880 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 694 /1000;  Training Loss: 1.261228 ; Training Acc: 43.640\n",
      "Iteration: 694 /1000;  Testing Loss: 1.790440 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 695 /1000;  Training Loss: 1.344716 ; Training Acc: 38.748\n",
      "Iteration: 695 /1000;  Testing Loss: 1.760930 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 696 /1000;  Training Loss: 1.312557 ; Training Acc: 41.683\n",
      "Iteration: 696 /1000;  Testing Loss: 1.754740 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 697 /1000;  Training Loss: 1.269762 ; Training Acc: 42.661\n",
      "Iteration: 697 /1000;  Testing Loss: 1.764218 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 698 /1000;  Training Loss: 1.275131 ; Training Acc: 40.900\n",
      "Iteration: 698 /1000;  Testing Loss: 1.746984 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 699 /1000;  Training Loss: 1.260192 ; Training Acc: 43.053\n",
      "Iteration: 699 /1000;  Testing Loss: 1.743713 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 700 /1000;  Training Loss: 1.284965 ; Training Acc: 40.900\n",
      "Iteration: 700 /1000;  Testing Loss: 1.744639 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 701 /1000;  Training Loss: 1.265811 ; Training Acc: 42.857\n",
      "Iteration: 701 /1000;  Testing Loss: 1.754736 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 702 /1000;  Training Loss: 1.250342 ; Training Acc: 43.249\n",
      "Iteration: 702 /1000;  Testing Loss: 1.747860 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 703 /1000;  Training Loss: 1.261836 ; Training Acc: 41.683\n",
      "Iteration: 703 /1000;  Testing Loss: 1.761164 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 704 /1000;  Training Loss: 1.290253 ; Training Acc: 41.096\n",
      "Iteration: 704 /1000;  Testing Loss: 1.782193 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 705 /1000;  Training Loss: 1.255284 ; Training Acc: 43.444\n",
      "Iteration: 705 /1000;  Testing Loss: 1.766773 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 706 /1000;  Training Loss: 1.266044 ; Training Acc: 42.661\n",
      "Iteration: 706 /1000;  Testing Loss: 1.750417 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 707 /1000;  Training Loss: 1.302580 ; Training Acc: 39.530\n",
      "Iteration: 707 /1000;  Testing Loss: 1.778139 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 708 /1000;  Training Loss: 1.269667 ; Training Acc: 41.879\n",
      "Iteration: 708 /1000;  Testing Loss: 1.755969 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 709 /1000;  Training Loss: 1.273624 ; Training Acc: 41.487\n",
      "Iteration: 709 /1000;  Testing Loss: 1.745007 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 710 /1000;  Training Loss: 1.245080 ; Training Acc: 42.466\n",
      "Iteration: 710 /1000;  Testing Loss: 1.746157 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 711 /1000;  Training Loss: 1.254909 ; Training Acc: 42.074\n",
      "Iteration: 711 /1000;  Testing Loss: 1.782051 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 712 /1000;  Training Loss: 1.256310 ; Training Acc: 42.466\n",
      "Iteration: 712 /1000;  Testing Loss: 1.753662 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 713 /1000;  Training Loss: 1.274831 ; Training Acc: 41.683\n",
      "Iteration: 713 /1000;  Testing Loss: 1.746899 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 714 /1000;  Training Loss: 1.247663 ; Training Acc: 43.444\n",
      "Iteration: 714 /1000;  Testing Loss: 1.821797 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 715 /1000;  Training Loss: 1.269119 ; Training Acc: 43.053\n",
      "Iteration: 715 /1000;  Testing Loss: 1.752753 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 716 /1000;  Training Loss: 1.266429 ; Training Acc: 42.074\n",
      "Iteration: 716 /1000;  Testing Loss: 1.770437 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 717 /1000;  Training Loss: 1.326639 ; Training Acc: 38.552\n",
      "Iteration: 717 /1000;  Testing Loss: 1.817808 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 718 /1000;  Training Loss: 1.283072 ; Training Acc: 42.074\n",
      "Iteration: 718 /1000;  Testing Loss: 1.818308 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 719 /1000;  Training Loss: 1.252328 ; Training Acc: 43.249\n",
      "Iteration: 719 /1000;  Testing Loss: 1.750686 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 720 /1000;  Training Loss: 1.248901 ; Training Acc: 42.857\n",
      "Iteration: 720 /1000;  Testing Loss: 1.763858 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 721 /1000;  Training Loss: 1.305933 ; Training Acc: 37.965\n",
      "Iteration: 721 /1000;  Testing Loss: 1.781006 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 722 /1000;  Training Loss: 1.289903 ; Training Acc: 42.270\n",
      "Iteration: 722 /1000;  Testing Loss: 1.745102 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 723 /1000;  Training Loss: 1.276443 ; Training Acc: 40.900\n",
      "Iteration: 723 /1000;  Testing Loss: 1.773983 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 724 /1000;  Training Loss: 1.250840 ; Training Acc: 42.661\n",
      "Iteration: 724 /1000;  Testing Loss: 1.745314 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 725 /1000;  Training Loss: 1.251976 ; Training Acc: 43.053\n",
      "Iteration: 725 /1000;  Testing Loss: 1.792664 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 726 /1000;  Training Loss: 1.311942 ; Training Acc: 39.530\n",
      "Iteration: 726 /1000;  Testing Loss: 1.750003 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 727 /1000;  Training Loss: 1.297450 ; Training Acc: 40.705\n",
      "Iteration: 727 /1000;  Testing Loss: 1.756325 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 728 /1000;  Training Loss: 1.279551 ; Training Acc: 42.857\n",
      "Iteration: 728 /1000;  Testing Loss: 1.742634 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 729 /1000;  Training Loss: 1.291227 ; Training Acc: 41.292\n",
      "Iteration: 729 /1000;  Testing Loss: 1.793218 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 730 /1000;  Training Loss: 1.275722 ; Training Acc: 41.683\n",
      "Iteration: 730 /1000;  Testing Loss: 1.777213 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 731 /1000;  Training Loss: 1.246580 ; Training Acc: 42.466\n",
      "Iteration: 731 /1000;  Testing Loss: 1.780790 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 732 /1000;  Training Loss: 1.249911 ; Training Acc: 42.661\n",
      "Iteration: 732 /1000;  Testing Loss: 1.773660 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 733 /1000;  Training Loss: 1.255567 ; Training Acc: 41.292\n",
      "Iteration: 733 /1000;  Testing Loss: 1.741041 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 734 /1000;  Training Loss: 1.239766 ; Training Acc: 42.466\n",
      "Iteration: 734 /1000;  Testing Loss: 1.750053 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 735 /1000;  Training Loss: 1.240166 ; Training Acc: 42.661\n",
      "Iteration: 735 /1000;  Testing Loss: 1.779232 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 736 /1000;  Training Loss: 1.230949 ; Training Acc: 44.031\n",
      "Iteration: 736 /1000;  Testing Loss: 1.743818 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 737 /1000;  Training Loss: 1.259595 ; Training Acc: 41.879\n",
      "Iteration: 737 /1000;  Testing Loss: 1.747460 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 738 /1000;  Training Loss: 1.242498 ; Training Acc: 43.053\n",
      "Iteration: 738 /1000;  Testing Loss: 1.887560 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 739 /1000;  Training Loss: 1.260752 ; Training Acc: 41.292\n",
      "Iteration: 739 /1000;  Testing Loss: 1.778476 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 740 /1000;  Training Loss: 1.243851 ; Training Acc: 43.249\n",
      "Iteration: 740 /1000;  Testing Loss: 1.799434 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 741 /1000;  Training Loss: 1.242334 ; Training Acc: 40.900\n",
      "Iteration: 741 /1000;  Testing Loss: 1.795615 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 742 /1000;  Training Loss: 1.267413 ; Training Acc: 42.661\n",
      "Iteration: 742 /1000;  Testing Loss: 1.747222 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 743 /1000;  Training Loss: 1.266352 ; Training Acc: 41.096\n",
      "Iteration: 743 /1000;  Testing Loss: 1.743411 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 744 /1000;  Training Loss: 1.241401 ; Training Acc: 42.270\n",
      "Iteration: 744 /1000;  Testing Loss: 1.749118 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 745 /1000;  Training Loss: 1.252773 ; Training Acc: 42.661\n",
      "Iteration: 745 /1000;  Testing Loss: 1.742248 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 746 /1000;  Training Loss: 1.277543 ; Training Acc: 41.487\n",
      "Iteration: 746 /1000;  Testing Loss: 1.837781 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 747 /1000;  Training Loss: 1.249162 ; Training Acc: 43.053\n",
      "Iteration: 747 /1000;  Testing Loss: 1.739698 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 748 /1000;  Training Loss: 1.263709 ; Training Acc: 41.879\n",
      "Iteration: 748 /1000;  Testing Loss: 1.815721 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 749 /1000;  Training Loss: 1.247507 ; Training Acc: 42.857\n",
      "Iteration: 749 /1000;  Testing Loss: 1.743853 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 750 /1000;  Training Loss: 1.246443 ; Training Acc: 41.487\n",
      "Iteration: 750 /1000;  Testing Loss: 1.742925 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 751 /1000;  Training Loss: 1.253968 ; Training Acc: 43.640\n",
      "Iteration: 751 /1000;  Testing Loss: 1.737677 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 752 /1000;  Training Loss: 1.241208 ; Training Acc: 42.661\n",
      "Iteration: 752 /1000;  Testing Loss: 1.828593 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 753 /1000;  Training Loss: 1.242146 ; Training Acc: 41.683\n",
      "Iteration: 753 /1000;  Testing Loss: 1.737132 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 754 /1000;  Training Loss: 1.238704 ; Training Acc: 43.444\n",
      "Iteration: 754 /1000;  Testing Loss: 1.738136 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 755 /1000;  Training Loss: 1.250567 ; Training Acc: 41.683\n",
      "Iteration: 755 /1000;  Testing Loss: 1.742851 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 756 /1000;  Training Loss: 1.231534 ; Training Acc: 43.444\n",
      "Iteration: 756 /1000;  Testing Loss: 1.758494 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 757 /1000;  Training Loss: 1.270398 ; Training Acc: 41.879\n",
      "Iteration: 757 /1000;  Testing Loss: 1.762796 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 758 /1000;  Training Loss: 1.322665 ; Training Acc: 38.552\n",
      "Iteration: 758 /1000;  Testing Loss: 1.792177 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 759 /1000;  Training Loss: 1.347532 ; Training Acc: 38.160\n",
      "Iteration: 759 /1000;  Testing Loss: 1.869473 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 760 /1000;  Training Loss: 1.250305 ; Training Acc: 42.857\n",
      "Iteration: 760 /1000;  Testing Loss: 1.731416 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 761 /1000;  Training Loss: 1.270583 ; Training Acc: 41.879\n",
      "Iteration: 761 /1000;  Testing Loss: 1.738960 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 762 /1000;  Training Loss: 1.298362 ; Training Acc: 39.922\n",
      "Iteration: 762 /1000;  Testing Loss: 1.742554 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 763 /1000;  Training Loss: 1.282050 ; Training Acc: 41.096\n",
      "Iteration: 763 /1000;  Testing Loss: 1.732680 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 764 /1000;  Training Loss: 1.240726 ; Training Acc: 42.466\n",
      "Iteration: 764 /1000;  Testing Loss: 1.749069 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 765 /1000;  Training Loss: 1.243459 ; Training Acc: 42.857\n",
      "Iteration: 765 /1000;  Testing Loss: 1.729327 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 766 /1000;  Training Loss: 1.230223 ; Training Acc: 42.270\n",
      "Iteration: 766 /1000;  Testing Loss: 1.735501 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 767 /1000;  Training Loss: 1.247273 ; Training Acc: 42.074\n",
      "Iteration: 767 /1000;  Testing Loss: 1.769921 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 768 /1000;  Training Loss: 1.270454 ; Training Acc: 41.879\n",
      "Iteration: 768 /1000;  Testing Loss: 1.823959 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 769 /1000;  Training Loss: 1.276239 ; Training Acc: 41.292\n",
      "Iteration: 769 /1000;  Testing Loss: 1.732321 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 770 /1000;  Training Loss: 1.304777 ; Training Acc: 39.335\n",
      "Iteration: 770 /1000;  Testing Loss: 1.755327 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 771 /1000;  Training Loss: 1.254567 ; Training Acc: 41.683\n",
      "Iteration: 771 /1000;  Testing Loss: 1.823014 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 772 /1000;  Training Loss: 1.241503 ; Training Acc: 42.270\n",
      "Iteration: 772 /1000;  Testing Loss: 1.844611 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 773 /1000;  Training Loss: 1.296448 ; Training Acc: 39.726\n",
      "Iteration: 773 /1000;  Testing Loss: 1.734015 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 774 /1000;  Training Loss: 1.280881 ; Training Acc: 40.509\n",
      "Iteration: 774 /1000;  Testing Loss: 1.743428 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 775 /1000;  Training Loss: 1.274417 ; Training Acc: 42.270\n",
      "Iteration: 775 /1000;  Testing Loss: 1.752442 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 776 /1000;  Training Loss: 1.254118 ; Training Acc: 43.444\n",
      "Iteration: 776 /1000;  Testing Loss: 1.828330 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 777 /1000;  Training Loss: 1.246948 ; Training Acc: 41.487\n",
      "Iteration: 777 /1000;  Testing Loss: 1.905046 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 778 /1000;  Training Loss: 1.247308 ; Training Acc: 41.292\n",
      "Iteration: 778 /1000;  Testing Loss: 1.730037 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 779 /1000;  Training Loss: 1.245174 ; Training Acc: 42.661\n",
      "Iteration: 779 /1000;  Testing Loss: 1.733623 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 780 /1000;  Training Loss: 1.241278 ; Training Acc: 45.010\n",
      "Iteration: 780 /1000;  Testing Loss: 1.735762 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 781 /1000;  Training Loss: 1.243062 ; Training Acc: 43.444\n",
      "Iteration: 781 /1000;  Testing Loss: 1.773427 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 782 /1000;  Training Loss: 1.236477 ; Training Acc: 44.031\n",
      "Iteration: 782 /1000;  Testing Loss: 1.742534 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 783 /1000;  Training Loss: 1.223958 ; Training Acc: 42.466\n",
      "Iteration: 783 /1000;  Testing Loss: 1.731474 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 784 /1000;  Training Loss: 1.238221 ; Training Acc: 41.879\n",
      "Iteration: 784 /1000;  Testing Loss: 1.744673 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 785 /1000;  Training Loss: 1.261130 ; Training Acc: 41.292\n",
      "Iteration: 785 /1000;  Testing Loss: 1.737426 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 786 /1000;  Training Loss: 1.230107 ; Training Acc: 43.053\n",
      "Iteration: 786 /1000;  Testing Loss: 1.756020 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 787 /1000;  Training Loss: 1.292271 ; Training Acc: 41.096\n",
      "Iteration: 787 /1000;  Testing Loss: 1.732858 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 788 /1000;  Training Loss: 1.239199 ; Training Acc: 41.879\n",
      "Iteration: 788 /1000;  Testing Loss: 1.728316 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 789 /1000;  Training Loss: 1.236503 ; Training Acc: 42.466\n",
      "Iteration: 789 /1000;  Testing Loss: 1.729078 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 790 /1000;  Training Loss: 1.243028 ; Training Acc: 43.053\n",
      "Iteration: 790 /1000;  Testing Loss: 1.776794 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 791 /1000;  Training Loss: 1.300136 ; Training Acc: 41.292\n",
      "Iteration: 791 /1000;  Testing Loss: 1.881326 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 792 /1000;  Training Loss: 1.279786 ; Training Acc: 40.705\n",
      "Iteration: 792 /1000;  Testing Loss: 1.727731 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 793 /1000;  Training Loss: 1.229755 ; Training Acc: 42.661\n",
      "Iteration: 793 /1000;  Testing Loss: 1.728240 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 794 /1000;  Training Loss: 1.232739 ; Training Acc: 42.661\n",
      "Iteration: 794 /1000;  Testing Loss: 1.737395 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 795 /1000;  Training Loss: 1.233430 ; Training Acc: 41.683\n",
      "Iteration: 795 /1000;  Testing Loss: 1.765431 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 796 /1000;  Training Loss: 1.272409 ; Training Acc: 42.466\n",
      "Iteration: 796 /1000;  Testing Loss: 1.826377 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 797 /1000;  Training Loss: 1.250480 ; Training Acc: 42.270\n",
      "Iteration: 797 /1000;  Testing Loss: 1.730151 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 798 /1000;  Training Loss: 1.253651 ; Training Acc: 42.270\n",
      "Iteration: 798 /1000;  Testing Loss: 1.727168 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 799 /1000;  Training Loss: 1.265550 ; Training Acc: 40.509\n",
      "Iteration: 799 /1000;  Testing Loss: 1.905568 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 800 /1000;  Training Loss: 1.271208 ; Training Acc: 39.922\n",
      "Iteration: 800 /1000;  Testing Loss: 1.725005 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 801 /1000;  Training Loss: 1.230231 ; Training Acc: 42.466\n",
      "Iteration: 801 /1000;  Testing Loss: 1.726195 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 802 /1000;  Training Loss: 1.226684 ; Training Acc: 45.401\n",
      "Iteration: 802 /1000;  Testing Loss: 1.726565 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 803 /1000;  Training Loss: 1.223534 ; Training Acc: 43.640\n",
      "Iteration: 803 /1000;  Testing Loss: 1.727409 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 804 /1000;  Training Loss: 1.258892 ; Training Acc: 42.270\n",
      "Iteration: 804 /1000;  Testing Loss: 1.974052 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 805 /1000;  Training Loss: 1.272996 ; Training Acc: 41.487\n",
      "Iteration: 805 /1000;  Testing Loss: 1.734417 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 806 /1000;  Training Loss: 1.262408 ; Training Acc: 41.096\n",
      "Iteration: 806 /1000;  Testing Loss: 1.746462 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 807 /1000;  Training Loss: 1.252284 ; Training Acc: 40.705\n",
      "Iteration: 807 /1000;  Testing Loss: 1.809918 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 808 /1000;  Training Loss: 1.335132 ; Training Acc: 39.922\n",
      "Iteration: 808 /1000;  Testing Loss: 1.750581 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 809 /1000;  Training Loss: 1.289304 ; Training Acc: 41.487\n",
      "Iteration: 809 /1000;  Testing Loss: 1.896882 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 810 /1000;  Training Loss: 1.250602 ; Training Acc: 42.074\n",
      "Iteration: 810 /1000;  Testing Loss: 1.756428 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 811 /1000;  Training Loss: 1.278270 ; Training Acc: 39.335\n",
      "Iteration: 811 /1000;  Testing Loss: 1.740880 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 812 /1000;  Training Loss: 1.289370 ; Training Acc: 40.313\n",
      "Iteration: 812 /1000;  Testing Loss: 1.725956 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 813 /1000;  Training Loss: 1.266202 ; Training Acc: 41.487\n",
      "Iteration: 813 /1000;  Testing Loss: 1.844355 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 814 /1000;  Training Loss: 1.306312 ; Training Acc: 40.117\n",
      "Iteration: 814 /1000;  Testing Loss: 1.719725 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 815 /1000;  Training Loss: 1.222455 ; Training Acc: 43.444\n",
      "Iteration: 815 /1000;  Testing Loss: 1.778571 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 816 /1000;  Training Loss: 1.236131 ; Training Acc: 43.249\n",
      "Iteration: 816 /1000;  Testing Loss: 1.722250 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 817 /1000;  Training Loss: 1.221870 ; Training Acc: 42.857\n",
      "Iteration: 817 /1000;  Testing Loss: 1.787623 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 818 /1000;  Training Loss: 1.223456 ; Training Acc: 44.031\n",
      "Iteration: 818 /1000;  Testing Loss: 1.719637 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 819 /1000;  Training Loss: 1.252396 ; Training Acc: 41.683\n",
      "Iteration: 819 /1000;  Testing Loss: 1.776639 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 820 /1000;  Training Loss: 1.223555 ; Training Acc: 43.836\n",
      "Iteration: 820 /1000;  Testing Loss: 1.720593 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 821 /1000;  Training Loss: 1.227211 ; Training Acc: 42.270\n",
      "Iteration: 821 /1000;  Testing Loss: 1.717860 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 822 /1000;  Training Loss: 1.232298 ; Training Acc: 42.270\n",
      "Iteration: 822 /1000;  Testing Loss: 1.752816 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 823 /1000;  Training Loss: 1.253488 ; Training Acc: 41.683\n",
      "Iteration: 823 /1000;  Testing Loss: 1.724414 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 824 /1000;  Training Loss: 1.225323 ; Training Acc: 43.640\n",
      "Iteration: 824 /1000;  Testing Loss: 1.727773 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 825 /1000;  Training Loss: 1.236433 ; Training Acc: 41.292\n",
      "Iteration: 825 /1000;  Testing Loss: 1.734963 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 826 /1000;  Training Loss: 1.241620 ; Training Acc: 40.705\n",
      "Iteration: 826 /1000;  Testing Loss: 1.732641 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 827 /1000;  Training Loss: 1.254681 ; Training Acc: 42.466\n",
      "Iteration: 827 /1000;  Testing Loss: 1.811998 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 828 /1000;  Training Loss: 1.229001 ; Training Acc: 43.053\n",
      "Iteration: 828 /1000;  Testing Loss: 1.802985 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 829 /1000;  Training Loss: 1.268712 ; Training Acc: 42.661\n",
      "Iteration: 829 /1000;  Testing Loss: 1.775753 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 830 /1000;  Training Loss: 1.235683 ; Training Acc: 42.270\n",
      "Iteration: 830 /1000;  Testing Loss: 1.823878 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 831 /1000;  Training Loss: 1.246028 ; Training Acc: 40.705\n",
      "Iteration: 831 /1000;  Testing Loss: 1.719958 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 832 /1000;  Training Loss: 1.220597 ; Training Acc: 44.227\n",
      "Iteration: 832 /1000;  Testing Loss: 1.724715 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 833 /1000;  Training Loss: 1.272898 ; Training Acc: 40.117\n",
      "Iteration: 833 /1000;  Testing Loss: 1.981209 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 834 /1000;  Training Loss: 1.242504 ; Training Acc: 42.270\n",
      "Iteration: 834 /1000;  Testing Loss: 1.737635 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 835 /1000;  Training Loss: 1.227777 ; Training Acc: 42.857\n",
      "Iteration: 835 /1000;  Testing Loss: 1.738557 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 836 /1000;  Training Loss: 1.234795 ; Training Acc: 43.249\n",
      "Iteration: 836 /1000;  Testing Loss: 1.818213 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 837 /1000;  Training Loss: 1.228856 ; Training Acc: 42.661\n",
      "Iteration: 837 /1000;  Testing Loss: 1.724651 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 838 /1000;  Training Loss: 1.217866 ; Training Acc: 44.031\n",
      "Iteration: 838 /1000;  Testing Loss: 1.725949 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 839 /1000;  Training Loss: 1.240965 ; Training Acc: 43.249\n",
      "Iteration: 839 /1000;  Testing Loss: 1.783144 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 840 /1000;  Training Loss: 1.340467 ; Training Acc: 39.139\n",
      "Iteration: 840 /1000;  Testing Loss: 1.781399 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 841 /1000;  Training Loss: 1.236043 ; Training Acc: 41.683\n",
      "Iteration: 841 /1000;  Testing Loss: 1.745110 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 842 /1000;  Training Loss: 1.216281 ; Training Acc: 43.444\n",
      "Iteration: 842 /1000;  Testing Loss: 1.717379 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 843 /1000;  Training Loss: 1.221809 ; Training Acc: 42.857\n",
      "Iteration: 843 /1000;  Testing Loss: 1.721058 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 844 /1000;  Training Loss: 1.216902 ; Training Acc: 42.270\n",
      "Iteration: 844 /1000;  Testing Loss: 1.799937 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 845 /1000;  Training Loss: 1.217101 ; Training Acc: 44.423\n",
      "Iteration: 845 /1000;  Testing Loss: 1.718765 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 846 /1000;  Training Loss: 1.214987 ; Training Acc: 45.010\n",
      "Iteration: 846 /1000;  Testing Loss: 1.724131 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 847 /1000;  Training Loss: 1.226022 ; Training Acc: 42.270\n",
      "Iteration: 847 /1000;  Testing Loss: 1.866215 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 848 /1000;  Training Loss: 1.224020 ; Training Acc: 44.031\n",
      "Iteration: 848 /1000;  Testing Loss: 1.720945 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 849 /1000;  Training Loss: 1.223911 ; Training Acc: 42.270\n",
      "Iteration: 849 /1000;  Testing Loss: 1.886505 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 850 /1000;  Training Loss: 1.236358 ; Training Acc: 42.661\n",
      "Iteration: 850 /1000;  Testing Loss: 1.718439 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 851 /1000;  Training Loss: 1.249421 ; Training Acc: 43.444\n",
      "Iteration: 851 /1000;  Testing Loss: 1.772857 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 852 /1000;  Training Loss: 1.247666 ; Training Acc: 41.487\n",
      "Iteration: 852 /1000;  Testing Loss: 1.740837 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 853 /1000;  Training Loss: 1.241152 ; Training Acc: 42.074\n",
      "Iteration: 853 /1000;  Testing Loss: 1.714076 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 854 /1000;  Training Loss: 1.204856 ; Training Acc: 44.227\n",
      "Iteration: 854 /1000;  Testing Loss: 1.949225 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 855 /1000;  Training Loss: 1.278230 ; Training Acc: 43.053\n",
      "Iteration: 855 /1000;  Testing Loss: 1.776923 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 856 /1000;  Training Loss: 1.268252 ; Training Acc: 39.530\n",
      "Iteration: 856 /1000;  Testing Loss: 2.051388 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 857 /1000;  Training Loss: 1.271102 ; Training Acc: 38.356\n",
      "Iteration: 857 /1000;  Testing Loss: 1.711261 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 858 /1000;  Training Loss: 1.245937 ; Training Acc: 42.857\n",
      "Iteration: 858 /1000;  Testing Loss: 1.724110 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 859 /1000;  Training Loss: 1.252698 ; Training Acc: 43.249\n",
      "Iteration: 859 /1000;  Testing Loss: 1.728018 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 860 /1000;  Training Loss: 1.355097 ; Training Acc: 37.573\n",
      "Iteration: 860 /1000;  Testing Loss: 1.739424 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 861 /1000;  Training Loss: 1.259092 ; Training Acc: 42.661\n",
      "Iteration: 861 /1000;  Testing Loss: 1.705207 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 862 /1000;  Training Loss: 1.227068 ; Training Acc: 43.640\n",
      "Iteration: 862 /1000;  Testing Loss: 1.837536 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 863 /1000;  Training Loss: 1.211843 ; Training Acc: 43.640\n",
      "Iteration: 863 /1000;  Testing Loss: 1.836252 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 864 /1000;  Training Loss: 1.227480 ; Training Acc: 42.661\n",
      "Iteration: 864 /1000;  Testing Loss: 1.730508 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 865 /1000;  Training Loss: 1.211451 ; Training Acc: 44.423\n",
      "Iteration: 865 /1000;  Testing Loss: 1.707563 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 866 /1000;  Training Loss: 1.205589 ; Training Acc: 44.618\n",
      "Iteration: 866 /1000;  Testing Loss: 1.788005 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 867 /1000;  Training Loss: 1.246062 ; Training Acc: 41.292\n",
      "Iteration: 867 /1000;  Testing Loss: 1.780807 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 868 /1000;  Training Loss: 1.218306 ; Training Acc: 43.053\n",
      "Iteration: 868 /1000;  Testing Loss: 1.793051 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 869 /1000;  Training Loss: 1.226547 ; Training Acc: 42.661\n",
      "Iteration: 869 /1000;  Testing Loss: 1.721704 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 870 /1000;  Training Loss: 1.273608 ; Training Acc: 40.313\n",
      "Iteration: 870 /1000;  Testing Loss: 1.773309 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 871 /1000;  Training Loss: 1.277927 ; Training Acc: 40.900\n",
      "Iteration: 871 /1000;  Testing Loss: 2.072365 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 872 /1000;  Training Loss: 1.267364 ; Training Acc: 41.879\n",
      "Iteration: 872 /1000;  Testing Loss: 1.706511 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 873 /1000;  Training Loss: 1.205938 ; Training Acc: 45.010\n",
      "Iteration: 873 /1000;  Testing Loss: 1.725032 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 874 /1000;  Training Loss: 1.211381 ; Training Acc: 42.857\n",
      "Iteration: 874 /1000;  Testing Loss: 1.725701 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 875 /1000;  Training Loss: 1.205916 ; Training Acc: 45.205\n",
      "Iteration: 875 /1000;  Testing Loss: 1.752538 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 876 /1000;  Training Loss: 1.219949 ; Training Acc: 41.683\n",
      "Iteration: 876 /1000;  Testing Loss: 1.707581 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 877 /1000;  Training Loss: 1.214128 ; Training Acc: 42.270\n",
      "Iteration: 877 /1000;  Testing Loss: 1.789273 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 878 /1000;  Training Loss: 1.221235 ; Training Acc: 43.444\n",
      "Iteration: 878 /1000;  Testing Loss: 1.802914 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 879 /1000;  Training Loss: 1.221393 ; Training Acc: 43.249\n",
      "Iteration: 879 /1000;  Testing Loss: 1.722818 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 880 /1000;  Training Loss: 1.223500 ; Training Acc: 42.074\n",
      "Iteration: 880 /1000;  Testing Loss: 1.722637 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 881 /1000;  Training Loss: 1.209862 ; Training Acc: 44.031\n",
      "Iteration: 881 /1000;  Testing Loss: 1.764223 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 882 /1000;  Training Loss: 1.198152 ; Training Acc: 43.249\n",
      "Iteration: 882 /1000;  Testing Loss: 1.715043 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 883 /1000;  Training Loss: 1.199896 ; Training Acc: 44.227\n",
      "Iteration: 883 /1000;  Testing Loss: 1.773162 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 884 /1000;  Training Loss: 1.246150 ; Training Acc: 40.705\n",
      "Iteration: 884 /1000;  Testing Loss: 1.714626 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 885 /1000;  Training Loss: 1.204138 ; Training Acc: 45.401\n",
      "Iteration: 885 /1000;  Testing Loss: 1.714793 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 886 /1000;  Training Loss: 1.200953 ; Training Acc: 44.618\n",
      "Iteration: 886 /1000;  Testing Loss: 1.748116 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 887 /1000;  Training Loss: 1.204222 ; Training Acc: 44.227\n",
      "Iteration: 887 /1000;  Testing Loss: 1.724412 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 888 /1000;  Training Loss: 1.218444 ; Training Acc: 41.879\n",
      "Iteration: 888 /1000;  Testing Loss: 1.753619 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 889 /1000;  Training Loss: 1.225484 ; Training Acc: 43.444\n",
      "Iteration: 889 /1000;  Testing Loss: 1.717065 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 890 /1000;  Training Loss: 1.210699 ; Training Acc: 45.010\n",
      "Iteration: 890 /1000;  Testing Loss: 1.747448 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 891 /1000;  Training Loss: 1.194586 ; Training Acc: 44.814\n",
      "Iteration: 891 /1000;  Testing Loss: 1.712919 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 892 /1000;  Training Loss: 1.209804 ; Training Acc: 42.857\n",
      "Iteration: 892 /1000;  Testing Loss: 1.729928 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 893 /1000;  Training Loss: 1.207022 ; Training Acc: 44.227\n",
      "Iteration: 893 /1000;  Testing Loss: 1.724773 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 894 /1000;  Training Loss: 1.216758 ; Training Acc: 43.444\n",
      "Iteration: 894 /1000;  Testing Loss: 1.737267 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 895 /1000;  Training Loss: 1.222105 ; Training Acc: 43.640\n",
      "Iteration: 895 /1000;  Testing Loss: 1.759687 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 896 /1000;  Training Loss: 1.210598 ; Training Acc: 43.444\n",
      "Iteration: 896 /1000;  Testing Loss: 1.714834 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 897 /1000;  Training Loss: 1.199851 ; Training Acc: 44.814\n",
      "Iteration: 897 /1000;  Testing Loss: 1.932036 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 898 /1000;  Training Loss: 1.226500 ; Training Acc: 42.466\n",
      "Iteration: 898 /1000;  Testing Loss: 1.724877 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 899 /1000;  Training Loss: 1.208648 ; Training Acc: 42.857\n",
      "Iteration: 899 /1000;  Testing Loss: 1.723225 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 900 /1000;  Training Loss: 1.206787 ; Training Acc: 43.444\n",
      "Iteration: 900 /1000;  Testing Loss: 1.715785 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 901 /1000;  Training Loss: 1.196655 ; Training Acc: 43.444\n",
      "Iteration: 901 /1000;  Testing Loss: 1.792689 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 902 /1000;  Training Loss: 1.197431 ; Training Acc: 44.423\n",
      "Iteration: 902 /1000;  Testing Loss: 1.765183 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 903 /1000;  Training Loss: 1.201122 ; Training Acc: 43.836\n",
      "Iteration: 903 /1000;  Testing Loss: 1.792268 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 904 /1000;  Training Loss: 1.309374 ; Training Acc: 38.356\n",
      "Iteration: 904 /1000;  Testing Loss: 1.717042 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 905 /1000;  Training Loss: 1.302127 ; Training Acc: 39.922\n",
      "Iteration: 905 /1000;  Testing Loss: 1.732570 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 906 /1000;  Training Loss: 1.215368 ; Training Acc: 44.618\n",
      "Iteration: 906 /1000;  Testing Loss: 1.710153 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 907 /1000;  Training Loss: 1.194724 ; Training Acc: 44.618\n",
      "Iteration: 907 /1000;  Testing Loss: 1.698651 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 908 /1000;  Training Loss: 1.204345 ; Training Acc: 43.444\n",
      "Iteration: 908 /1000;  Testing Loss: 1.700156 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 909 /1000;  Training Loss: 1.203035 ; Training Acc: 45.010\n",
      "Iteration: 909 /1000;  Testing Loss: 1.701222 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 910 /1000;  Training Loss: 1.205529 ; Training Acc: 44.227\n",
      "Iteration: 910 /1000;  Testing Loss: 1.777611 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 911 /1000;  Training Loss: 1.240666 ; Training Acc: 42.466\n",
      "Iteration: 911 /1000;  Testing Loss: 1.860676 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 912 /1000;  Training Loss: 1.249419 ; Training Acc: 41.683\n",
      "Iteration: 912 /1000;  Testing Loss: 1.877935 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 913 /1000;  Training Loss: 1.278723 ; Training Acc: 38.943\n",
      "Iteration: 913 /1000;  Testing Loss: 1.718414 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 914 /1000;  Training Loss: 1.194401 ; Training Acc: 43.640\n",
      "Iteration: 914 /1000;  Testing Loss: 1.721276 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 915 /1000;  Training Loss: 1.195409 ; Training Acc: 44.031\n",
      "Iteration: 915 /1000;  Testing Loss: 1.707430 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 916 /1000;  Training Loss: 1.199413 ; Training Acc: 45.205\n",
      "Iteration: 916 /1000;  Testing Loss: 1.741566 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 917 /1000;  Training Loss: 1.260446 ; Training Acc: 40.313\n",
      "Iteration: 917 /1000;  Testing Loss: 1.696967 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 918 /1000;  Training Loss: 1.262882 ; Training Acc: 38.356\n",
      "Iteration: 918 /1000;  Testing Loss: 1.881715 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 919 /1000;  Training Loss: 1.308380 ; Training Acc: 39.530\n",
      "Iteration: 919 /1000;  Testing Loss: 1.875255 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 920 /1000;  Training Loss: 1.288888 ; Training Acc: 39.335\n",
      "Iteration: 920 /1000;  Testing Loss: 1.755012 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 921 /1000;  Training Loss: 1.207747 ; Training Acc: 43.836\n",
      "Iteration: 921 /1000;  Testing Loss: 1.967221 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 922 /1000;  Training Loss: 1.235548 ; Training Acc: 43.053\n",
      "Iteration: 922 /1000;  Testing Loss: 1.694234 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 923 /1000;  Training Loss: 1.201176 ; Training Acc: 42.857\n",
      "Iteration: 923 /1000;  Testing Loss: 1.737192 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 924 /1000;  Training Loss: 1.193746 ; Training Acc: 43.444\n",
      "Iteration: 924 /1000;  Testing Loss: 1.702427 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 925 /1000;  Training Loss: 1.189529 ; Training Acc: 44.814\n",
      "Iteration: 925 /1000;  Testing Loss: 1.746678 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 926 /1000;  Training Loss: 1.210268 ; Training Acc: 42.857\n",
      "Iteration: 926 /1000;  Testing Loss: 1.775491 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 927 /1000;  Training Loss: 1.209145 ; Training Acc: 44.814\n",
      "Iteration: 927 /1000;  Testing Loss: 1.696162 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 928 /1000;  Training Loss: 1.226335 ; Training Acc: 42.466\n",
      "Iteration: 928 /1000;  Testing Loss: 1.695599 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 929 /1000;  Training Loss: 1.191697 ; Training Acc: 44.031\n",
      "Iteration: 929 /1000;  Testing Loss: 1.770469 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 930 /1000;  Training Loss: 1.194077 ; Training Acc: 44.227\n",
      "Iteration: 930 /1000;  Testing Loss: 1.726401 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 931 /1000;  Training Loss: 1.189356 ; Training Acc: 44.814\n",
      "Iteration: 931 /1000;  Testing Loss: 1.709342 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 932 /1000;  Training Loss: 1.192124 ; Training Acc: 43.836\n",
      "Iteration: 932 /1000;  Testing Loss: 1.704574 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 933 /1000;  Training Loss: 1.205369 ; Training Acc: 43.640\n",
      "Iteration: 933 /1000;  Testing Loss: 1.704485 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 934 /1000;  Training Loss: 1.202846 ; Training Acc: 43.640\n",
      "Iteration: 934 /1000;  Testing Loss: 1.775634 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 935 /1000;  Training Loss: 1.235059 ; Training Acc: 40.705\n",
      "Iteration: 935 /1000;  Testing Loss: 1.702926 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 936 /1000;  Training Loss: 1.255029 ; Training Acc: 42.270\n",
      "Iteration: 936 /1000;  Testing Loss: 1.701893 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 937 /1000;  Training Loss: 1.197180 ; Training Acc: 43.444\n",
      "Iteration: 937 /1000;  Testing Loss: 1.706355 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 938 /1000;  Training Loss: 1.187888 ; Training Acc: 44.618\n",
      "Iteration: 938 /1000;  Testing Loss: 1.710077 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 939 /1000;  Training Loss: 1.237571 ; Training Acc: 40.705\n",
      "Iteration: 939 /1000;  Testing Loss: 1.904065 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 940 /1000;  Training Loss: 1.227711 ; Training Acc: 42.270\n",
      "Iteration: 940 /1000;  Testing Loss: 1.702586 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 941 /1000;  Training Loss: 1.218203 ; Training Acc: 44.814\n",
      "Iteration: 941 /1000;  Testing Loss: 1.694609 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 942 /1000;  Training Loss: 1.187016 ; Training Acc: 45.597\n",
      "Iteration: 942 /1000;  Testing Loss: 1.693421 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 943 /1000;  Training Loss: 1.185912 ; Training Acc: 45.010\n",
      "Iteration: 943 /1000;  Testing Loss: 1.754397 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 944 /1000;  Training Loss: 1.198947 ; Training Acc: 44.814\n",
      "Iteration: 944 /1000;  Testing Loss: 1.695479 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 945 /1000;  Training Loss: 1.215021 ; Training Acc: 43.249\n",
      "Iteration: 945 /1000;  Testing Loss: 1.696369 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 946 /1000;  Training Loss: 1.294555 ; Training Acc: 39.922\n",
      "Iteration: 946 /1000;  Testing Loss: 1.750962 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 947 /1000;  Training Loss: 1.201630 ; Training Acc: 44.618\n",
      "Iteration: 947 /1000;  Testing Loss: 1.823410 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 948 /1000;  Training Loss: 1.200874 ; Training Acc: 42.661\n",
      "Iteration: 948 /1000;  Testing Loss: 1.735132 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 949 /1000;  Training Loss: 1.182576 ; Training Acc: 45.205\n",
      "Iteration: 949 /1000;  Testing Loss: 1.703403 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 950 /1000;  Training Loss: 1.195736 ; Training Acc: 43.640\n",
      "Iteration: 950 /1000;  Testing Loss: 1.697770 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 951 /1000;  Training Loss: 1.188798 ; Training Acc: 43.640\n",
      "Iteration: 951 /1000;  Testing Loss: 1.695853 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 952 /1000;  Training Loss: 1.215603 ; Training Acc: 42.270\n",
      "Iteration: 952 /1000;  Testing Loss: 1.896833 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 953 /1000;  Training Loss: 1.253514 ; Training Acc: 40.900\n",
      "Iteration: 953 /1000;  Testing Loss: 1.972874 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 954 /1000;  Training Loss: 1.258569 ; Training Acc: 40.705\n",
      "Iteration: 954 /1000;  Testing Loss: 1.701282 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 955 /1000;  Training Loss: 1.223201 ; Training Acc: 44.227\n",
      "Iteration: 955 /1000;  Testing Loss: 1.688529 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 956 /1000;  Training Loss: 1.190839 ; Training Acc: 45.793\n",
      "Iteration: 956 /1000;  Testing Loss: 1.703037 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 957 /1000;  Training Loss: 1.196105 ; Training Acc: 42.857\n",
      "Iteration: 957 /1000;  Testing Loss: 1.688933 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 958 /1000;  Training Loss: 1.232939 ; Training Acc: 40.117\n",
      "Iteration: 958 /1000;  Testing Loss: 1.703339 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 959 /1000;  Training Loss: 1.244838 ; Training Acc: 41.096\n",
      "Iteration: 959 /1000;  Testing Loss: 1.740354 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 960 /1000;  Training Loss: 1.189909 ; Training Acc: 42.857\n",
      "Iteration: 960 /1000;  Testing Loss: 1.766867 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 961 /1000;  Training Loss: 1.211232 ; Training Acc: 42.857\n",
      "Iteration: 961 /1000;  Testing Loss: 1.821289 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 962 /1000;  Training Loss: 1.237122 ; Training Acc: 41.683\n",
      "Iteration: 962 /1000;  Testing Loss: 1.685208 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 963 /1000;  Training Loss: 1.206687 ; Training Acc: 43.249\n",
      "Iteration: 963 /1000;  Testing Loss: 1.693883 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 964 /1000;  Training Loss: 1.185107 ; Training Acc: 45.010\n",
      "Iteration: 964 /1000;  Testing Loss: 1.689327 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 965 /1000;  Training Loss: 1.199844 ; Training Acc: 43.053\n",
      "Iteration: 965 /1000;  Testing Loss: 1.686871 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 966 /1000;  Training Loss: 1.201761 ; Training Acc: 43.640\n",
      "Iteration: 966 /1000;  Testing Loss: 1.689311 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 967 /1000;  Training Loss: 1.197449 ; Training Acc: 44.423\n",
      "Iteration: 967 /1000;  Testing Loss: 1.731233 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 968 /1000;  Training Loss: 1.191276 ; Training Acc: 44.227\n",
      "Iteration: 968 /1000;  Testing Loss: 1.734400 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 969 /1000;  Training Loss: 1.187010 ; Training Acc: 44.423\n",
      "Iteration: 969 /1000;  Testing Loss: 1.712799 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 970 /1000;  Training Loss: 1.178278 ; Training Acc: 45.793\n",
      "Iteration: 970 /1000;  Testing Loss: 1.690660 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 971 /1000;  Training Loss: 1.178342 ; Training Acc: 45.205\n",
      "Iteration: 971 /1000;  Testing Loss: 1.705137 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 972 /1000;  Training Loss: 1.176172 ; Training Acc: 45.205\n",
      "Iteration: 972 /1000;  Testing Loss: 1.693373 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 973 /1000;  Training Loss: 1.196684 ; Training Acc: 44.423\n",
      "Iteration: 973 /1000;  Testing Loss: 1.695337 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 974 /1000;  Training Loss: 1.334716 ; Training Acc: 38.552\n",
      "Iteration: 974 /1000;  Testing Loss: 2.195943 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 975 /1000;  Training Loss: 1.335404 ; Training Acc: 37.965\n",
      "Iteration: 975 /1000;  Testing Loss: 1.682438 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 976 /1000;  Training Loss: 1.233852 ; Training Acc: 43.053\n",
      "Iteration: 976 /1000;  Testing Loss: 1.712044 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 977 /1000;  Training Loss: 1.211070 ; Training Acc: 43.444\n",
      "Iteration: 977 /1000;  Testing Loss: 1.733001 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 978 /1000;  Training Loss: 1.182216 ; Training Acc: 44.618\n",
      "Iteration: 978 /1000;  Testing Loss: 1.743818 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 979 /1000;  Training Loss: 1.182013 ; Training Acc: 44.227\n",
      "Iteration: 979 /1000;  Testing Loss: 1.709586 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 980 /1000;  Training Loss: 1.180047 ; Training Acc: 43.444\n",
      "Iteration: 980 /1000;  Testing Loss: 1.766700 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 981 /1000;  Training Loss: 1.184817 ; Training Acc: 44.227\n",
      "Iteration: 981 /1000;  Testing Loss: 1.728593 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 982 /1000;  Training Loss: 1.178203 ; Training Acc: 43.249\n",
      "Iteration: 982 /1000;  Testing Loss: 1.681465 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 983 /1000;  Training Loss: 1.222287 ; Training Acc: 41.487\n",
      "Iteration: 983 /1000;  Testing Loss: 1.679338 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 984 /1000;  Training Loss: 1.205103 ; Training Acc: 41.096\n",
      "Iteration: 984 /1000;  Testing Loss: 1.682203 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 985 /1000;  Training Loss: 1.298470 ; Training Acc: 38.160\n",
      "Iteration: 985 /1000;  Testing Loss: 1.692465 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 986 /1000;  Training Loss: 1.235193 ; Training Acc: 42.466\n",
      "Iteration: 986 /1000;  Testing Loss: 1.836492 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 987 /1000;  Training Loss: 1.178811 ; Training Acc: 44.423\n",
      "Iteration: 987 /1000;  Testing Loss: 1.713615 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 988 /1000;  Training Loss: 1.191396 ; Training Acc: 44.031\n",
      "Iteration: 988 /1000;  Testing Loss: 1.758982 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 989 /1000;  Training Loss: 1.184013 ; Training Acc: 44.618\n",
      "Iteration: 989 /1000;  Testing Loss: 1.729720 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 990 /1000;  Training Loss: 1.175291 ; Training Acc: 45.010\n",
      "Iteration: 990 /1000;  Testing Loss: 1.692010 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 991 /1000;  Training Loss: 1.185711 ; Training Acc: 42.857\n",
      "Iteration: 991 /1000;  Testing Loss: 1.688054 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 992 /1000;  Training Loss: 1.175469 ; Training Acc: 45.597\n",
      "Iteration: 992 /1000;  Testing Loss: 1.695119 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 993 /1000;  Training Loss: 1.208574 ; Training Acc: 44.031\n",
      "Iteration: 993 /1000;  Testing Loss: 1.959872 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 994 /1000;  Training Loss: 1.233603 ; Training Acc: 41.683\n",
      "Iteration: 994 /1000;  Testing Loss: 1.754722 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 995 /1000;  Training Loss: 1.199876 ; Training Acc: 43.640\n",
      "Iteration: 995 /1000;  Testing Loss: 1.712015 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 996 /1000;  Training Loss: 1.202358 ; Training Acc: 42.270\n",
      "Iteration: 996 /1000;  Testing Loss: 1.859041 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 997 /1000;  Training Loss: 1.199273 ; Training Acc: 43.053\n",
      "Iteration: 997 /1000;  Testing Loss: 1.721840 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 998 /1000;  Training Loss: 1.187286 ; Training Acc: 43.444\n",
      "Iteration: 998 /1000;  Testing Loss: 1.693890 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 999 /1000;  Training Loss: 1.171115 ; Training Acc: 45.597\n",
      "Iteration: 999 /1000;  Testing Loss: 1.723567 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 1000 /1000;  Training Loss: 1.199233 ; Training Acc: 43.836\n",
      "Iteration: 1000 /1000;  Testing Loss: 1.683842 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Training completed in 10m 29s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "bSize = 32 # Batch size\n",
    "L = 32 # Number of time steps\n",
    "\n",
    "bCount = len(trainShuffList)//bSize # Number of batches in train set\n",
    "lastBatch = len(trainShuffList)%bSize # Number of samples in last batch of train set\n",
    "\n",
    "test_bCount = len(testList)//bSize # Number of batches in test set\n",
    "test_lastBatch = len(testList)%bSize # Number of samples in last batch of test set\n",
    "\n",
    "# Lists for saving train/test loss and accuracy\n",
    "trainLoss = []\n",
    "trainAcc = []\n",
    "testLoss = []\n",
    "testAcc = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epochNum in range(epochs):\n",
    "    # Shuffling train data for each epoch\n",
    "    trainList = list(zip(trainShuffList, labelShuffList))\n",
    "    shuffle(trainList)\n",
    "    trainShuffList, labelShuffList = zip(*trainList)\n",
    "    \n",
    "    trainRunLoss = 0.0\n",
    "    testRunLoss = 0.0\n",
    "    trainRunCorr = 0\n",
    "    testRunCorr = 0\n",
    "    \n",
    "    epochStart = time.time()\n",
    "    \n",
    "    ## Train\n",
    "    # Load data tensors batchwise     \n",
    "    idx = 0    \n",
    "    for bNum in range(bCount):\n",
    "        first = True\n",
    "        # Loading one batch\n",
    "        for dNum in range(idx,idx+bSize):\n",
    "            if first:\n",
    "                loadData = torch.load(trainPath+trainShuffList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                batchData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchLabel = torch.Tensor([labelShuffList[dNum]]).long()                          \n",
    "                first = False                \n",
    "            else:\n",
    "                loadData = torch.load(trainPath+trainShuffList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                tempData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchData = torch.cat((batchData,tempData), dim=0)\n",
    "                batchLabel = torch.cat((batchLabel,torch.Tensor([labelShuffList[dNum]]).long()),dim=0)            \n",
    "        \n",
    "        # Train the network on current batch\n",
    "        net, tr_loss, tr_corr = train(net, batchData, batchLabel, optimizer, criterion)\n",
    "        trainRunLoss += tr_loss\n",
    "        trainRunCorr += tr_corr\n",
    "        idx += bSize\n",
    "        \n",
    "    # Loading last batch\n",
    "    if lastBatch != 0:        \n",
    "        first = True\n",
    "        for dNum in range(idx,idx+lastBatch):\n",
    "            if first:\n",
    "                loadData = torch.load(trainPath+trainShuffList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                batchData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchLabel = torch.Tensor([labelShuffList[dNum]]).long()\n",
    "                first = False                \n",
    "            else:\n",
    "                loadData = torch.load(trainPath+trainShuffList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                tempData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchData = torch.cat((batchData,tempData), dim=0)\n",
    "                batchLabel = torch.cat((batchLabel,torch.Tensor([labelShuffList[dNum]]).long()),dim=0)          \n",
    "        \n",
    "        # Training network on last batch\n",
    "        net, tr_loss, tr_corr = train(net, batchData, batchLabel, optimizer, criterion)\n",
    "        trainRunLoss += tr_loss\n",
    "        trainRunCorr += tr_corr\n",
    "    \n",
    "    # Average training loss and accuracy for each epoch\n",
    "    avgTrainLoss = trainRunLoss/bCount\n",
    "    trainLoss.append(avgTrainLoss)\n",
    "    avgTrainAcc = 100*float(trainRunCorr)/float(len(trainShuffList))\n",
    "    trainAcc.append(avgTrainAcc)\n",
    "    \n",
    "    ## Test\n",
    "    # Load data tensors batchwise     \n",
    "    idx = 0    \n",
    "    for bNum in range(test_bCount):\n",
    "        first = True\n",
    "        # Loading one batch\n",
    "        for dNum in range(idx,idx+bSize): \n",
    "            if first:\n",
    "                loadData = torch.load(testPath+testList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                batchData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchLabel = torch.Tensor([testLabelList[dNum]]).long()\n",
    "                first = False                \n",
    "            else:\n",
    "                loadData = torch.load(testPath+testList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                tempData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchData = torch.cat((batchData,tempData), dim=0)\n",
    "                batchLabel = torch.cat((batchLabel,torch.Tensor([testLabelList[dNum]]).long()),dim=0)            \n",
    "        \n",
    "        # Test the network on current batch\n",
    "        ts_loss, ts_corr = test(net, batchData, batchLabel, criterion)\n",
    "        testRunLoss += ts_loss\n",
    "        testRunCorr += ts_corr\n",
    "        idx += bSize\n",
    "     \n",
    "    # Loading last batch    \n",
    "    if test_lastBatch != 0:        \n",
    "        first = True\n",
    "        for dNum in range(idx,idx+test_lastBatch):\n",
    "            if first:\n",
    "                loadData = torch.load(testPath+testList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                batchData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)               \n",
    "                batchLabel = torch.Tensor([testLabelList[dNum]]).long()\n",
    "                first = False                \n",
    "            else:\n",
    "                loadData = torch.load(testPath+testList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                tempData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchData = torch.cat((batchData,tempData), dim=0)\n",
    "                batchLabel = torch.cat((batchLabel,torch.Tensor([testLabelList[dNum]]).long()),dim=0)          \n",
    "        \n",
    "        # Test network on last batch\n",
    "        ts_loss, ts_corr = test(net, batchData, batchLabel, criterion)\n",
    "        testRunLoss += ts_loss\n",
    "        testRunCorr += tr_corr\n",
    "        \n",
    "    # Average testing loss and accuracy for each epoch\n",
    "    avgTestLoss = testRunLoss/test_bCount\n",
    "    testLoss.append(avgTestLoss)\n",
    "    avgTestAcc = 100*float(testRunCorr)/float(len(testList))\n",
    "    testAcc.append(avgTestAcc)   \n",
    "\n",
    "    \n",
    "    # Plotting training loss vs Epochs\n",
    "    fig1 = plt.figure(1)        \n",
    "    plt.plot(range(epochNum+1),trainLoss,'r-',label='train')  \n",
    "    plt.plot(range(epochNum+1),testLoss,'g-',label='test') \n",
    "    if epochNum==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')   \n",
    "    # Plotting testing accuracy vs Epochs\n",
    "    fig2 = plt.figure(2)        \n",
    "    plt.plot(range(epochNum+1),trainAcc,'r-',label='train')    \n",
    "    plt.plot(range(epochNum+1),testAcc,'g-',label='test')        \n",
    "    if epochNum==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "    \n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('Iteration: {:.0f} /{:.0f};  Training Loss: {:.6f} ; Training Acc: {:.3f}'\\\n",
    "          .format(epochNum + 1,epochs, avgTrainLoss, avgTrainAcc))\n",
    "    print('Iteration: {:.0f} /{:.0f};  Testing Loss: {:.6f} ; Testing Acc: {:.3f}'\\\n",
    "          .format(epochNum + 1,epochs, avgTestLoss, avgTestAcc))\n",
    "    \n",
    "    print('Time consumed: {:.0f}m {:.0f}s'.format(epochEnd//60,epochEnd%60))\n",
    "end = time.time()-start\n",
    "print('Training completed in {:.0f}m {:.0f}s'.format(end//60,end%60))    \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
